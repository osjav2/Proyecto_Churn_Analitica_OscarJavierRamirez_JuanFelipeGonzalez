2025-11-11 22:55:43,450:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 22:55:43,451:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 22:55:43,451:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 22:55:43,451:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 23:02:10,555:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 23:02:10,660:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 23:02:10,663:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 23:02:10,663:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 23:04:33,107:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\model_selection\_search.py:318: UserWarning: The total space of parameters 16 is smaller than n_iter=20. Running 16 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

2025-11-11 23:04:58,740:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\model_selection\_search.py:318: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

2025-11-11 23:05:43,195:INFO:PyCaret ClassificationExperiment
2025-11-11 23:05:43,195:INFO:Logging name: clf-default-name
2025-11-11 23:05:43,196:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-11 23:05:43,196:INFO:version 3.3.2
2025-11-11 23:05:43,196:INFO:Initializing setup()
2025-11-11 23:05:43,197:INFO:self.USI: 0bcf
2025-11-11 23:05:43,197:INFO:self._variable_keys: {'idx', '_available_plots', 'log_plots_param', 'X_train', 'html_param', 'target_param', 'y', 'fix_imbalance', 'exp_id', 'seed', 'y_train', 'memory', 'fold_shuffle_param', 'X_test', 'exp_name_log', '_ml_usecase', 'y_test', 'USI', 'X', 'fold_generator', 'fold_groups_param', 'data', 'n_jobs_param', 'pipeline', 'is_multiclass', 'gpu_param', 'logging_param', 'gpu_n_jobs_param'}
2025-11-11 23:05:43,197:INFO:Checking environment
2025-11-11 23:05:43,197:INFO:python_version: 3.9.10
2025-11-11 23:05:43,199:INFO:python_build: ('tags/v3.9.10:f2f3f53', 'Jan 17 2022 15:14:21')
2025-11-11 23:05:43,199:INFO:machine: AMD64
2025-11-11 23:05:43,199:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-11 23:05:43,205:INFO:Memory: svmem(total=42001428480, available=28302946304, percent=32.6, used=13698482176, free=28302946304)
2025-11-11 23:05:43,206:INFO:Physical Core: 16
2025-11-11 23:05:43,206:INFO:Logical Core: 16
2025-11-11 23:05:43,206:INFO:Checking libraries
2025-11-11 23:05:43,207:INFO:System:
2025-11-11 23:05:43,207:INFO:    python: 3.9.10 (tags/v3.9.10:f2f3f53, Jan 17 2022, 15:14:21) [MSC v.1929 64 bit (AMD64)]
2025-11-11 23:05:43,207:INFO:executable: C:\Users\usuario\PycharmProjects\PythonProject\.venv\Scripts\python.exe
2025-11-11 23:05:43,207:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-11 23:05:43,207:INFO:PyCaret required dependencies:
2025-11-11 23:05:43,209:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:05:43,313:INFO:                 pip: 25.3
2025-11-11 23:05:43,314:INFO:          setuptools: 80.3.1
2025-11-11 23:05:43,314:INFO:             pycaret: 3.3.2
2025-11-11 23:05:43,314:INFO:             IPython: 8.18.1
2025-11-11 23:05:43,314:INFO:          ipywidgets: 8.1.8
2025-11-11 23:05:43,314:INFO:                tqdm: 4.67.1
2025-11-11 23:05:43,314:INFO:               numpy: 1.26.4
2025-11-11 23:05:43,314:INFO:              pandas: 2.1.4
2025-11-11 23:05:43,314:INFO:              jinja2: 3.1.6
2025-11-11 23:05:43,314:INFO:               scipy: 1.11.4
2025-11-11 23:05:43,314:INFO:              joblib: 1.3.2
2025-11-11 23:05:43,314:INFO:             sklearn: 1.4.2
2025-11-11 23:05:43,314:INFO:                pyod: 2.0.5
2025-11-11 23:05:43,314:INFO:            imblearn: 0.12.4
2025-11-11 23:05:43,314:INFO:   category_encoders: 2.6.4
2025-11-11 23:05:43,314:INFO:            lightgbm: 4.6.0
2025-11-11 23:05:43,314:INFO:               numba: 0.60.0
2025-11-11 23:05:43,315:INFO:            requests: 2.32.5
2025-11-11 23:05:43,315:INFO:          matplotlib: 3.7.5
2025-11-11 23:05:43,315:INFO:          scikitplot: 0.3.7
2025-11-11 23:05:43,315:INFO:         yellowbrick: 1.5
2025-11-11 23:05:43,316:INFO:              plotly: 6.4.0
2025-11-11 23:05:43,316:INFO:    plotly-resampler: Not installed
2025-11-11 23:05:43,316:INFO:             kaleido: 1.2.0
2025-11-11 23:05:43,316:INFO:           schemdraw: 0.15
2025-11-11 23:05:43,316:INFO:         statsmodels: 0.14.5
2025-11-11 23:05:43,316:INFO:              sktime: 0.26.0
2025-11-11 23:05:43,316:INFO:               tbats: 1.1.3
2025-11-11 23:05:43,316:INFO:            pmdarima: 2.0.4
2025-11-11 23:05:43,316:INFO:              psutil: 7.1.3
2025-11-11 23:05:43,316:INFO:          markupsafe: 3.0.3
2025-11-11 23:05:43,316:INFO:             pickle5: Not installed
2025-11-11 23:05:43,316:INFO:         cloudpickle: 3.1.2
2025-11-11 23:05:43,316:INFO:         deprecation: 2.1.0
2025-11-11 23:05:43,316:INFO:              xxhash: 3.6.0
2025-11-11 23:05:43,316:INFO:           wurlitzer: Not installed
2025-11-11 23:05:43,316:INFO:PyCaret optional dependencies:
2025-11-11 23:05:43,407:INFO:                shap: Not installed
2025-11-11 23:05:43,407:INFO:           interpret: Not installed
2025-11-11 23:05:43,407:INFO:                umap: Not installed
2025-11-11 23:05:43,407:INFO:     ydata_profiling: Not installed
2025-11-11 23:05:43,407:INFO:  explainerdashboard: Not installed
2025-11-11 23:05:43,407:INFO:             autoviz: Not installed
2025-11-11 23:05:43,407:INFO:           fairlearn: Not installed
2025-11-11 23:05:43,407:INFO:          deepchecks: Not installed
2025-11-11 23:05:43,409:INFO:             xgboost: Not installed
2025-11-11 23:05:43,409:INFO:            catboost: Not installed
2025-11-11 23:05:43,409:INFO:              kmodes: Not installed
2025-11-11 23:05:43,409:INFO:             mlxtend: Not installed
2025-11-11 23:05:43,409:INFO:       statsforecast: Not installed
2025-11-11 23:05:43,409:INFO:        tune_sklearn: Not installed
2025-11-11 23:05:43,409:INFO:                 ray: Not installed
2025-11-11 23:05:43,409:INFO:            hyperopt: Not installed
2025-11-11 23:05:43,409:INFO:              optuna: Not installed
2025-11-11 23:05:43,409:INFO:               skopt: Not installed
2025-11-11 23:05:43,409:INFO:              mlflow: Not installed
2025-11-11 23:05:43,409:INFO:              gradio: Not installed
2025-11-11 23:05:43,409:INFO:             fastapi: Not installed
2025-11-11 23:05:43,409:INFO:             uvicorn: Not installed
2025-11-11 23:05:43,409:INFO:              m2cgen: Not installed
2025-11-11 23:05:43,409:INFO:           evidently: Not installed
2025-11-11 23:05:43,409:INFO:               fugue: Not installed
2025-11-11 23:05:43,409:INFO:           streamlit: Not installed
2025-11-11 23:05:43,409:INFO:             prophet: Not installed
2025-11-11 23:05:43,409:INFO:None
2025-11-11 23:05:43,409:INFO:Set up data.
2025-11-11 23:05:43,435:INFO:Set up folding strategy.
2025-11-11 23:05:43,435:INFO:Set up train/test split.
2025-11-11 23:05:43,461:INFO:Set up index.
2025-11-11 23:05:43,461:INFO:Assigning column types.
2025-11-11 23:05:43,474:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-11 23:05:43,549:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-11 23:05:43,559:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-11 23:05:43,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:05:43,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:05:43,680:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-11 23:05:43,682:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-11 23:05:43,721:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:05:43,805:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:05:43,805:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-11 23:05:43,867:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-11 23:05:43,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:05:43,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:05:43,961:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-11 23:05:43,995:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:05:43,995:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:05:43,995:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-11 23:05:44,098:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:05:44,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:05:44,197:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:05:44,197:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:05:44,200:INFO:Preparing preprocessing pipeline...
2025-11-11 23:05:44,204:INFO:Set up simple imputation.
2025-11-11 23:05:44,212:INFO:Set up encoding of ordinal features.
2025-11-11 23:05:44,217:INFO:Set up encoding of categorical features.
2025-11-11 23:05:44,440:INFO:Finished creating preprocessing pipeline.
2025-11-11 23:05:44,474:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\usuario\AppData\Local\Temp\2\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['education_level',
                                             'marital_status',
                                             'income_category',
                                             'card_category'],
                                    transformer=OneHotEncoder(cols=['education_level',
                                                                    'marital_status',
                                                                    'income_category',
                                                                    'card_category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-11-11 23:05:44,474:INFO:Creating final display dataframe.
2025-11-11 23:05:44,677:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target    attrition_flag
2                   Target type            Binary
3           Original data shape       (10127, 21)
4        Transformed data shape       (10127, 38)
5   Transformed train set shape        (7088, 38)
6    Transformed test set shape        (3039, 38)
7              Numeric features                15
8          Categorical features                 5
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              0bcf
2025-11-11 23:05:44,786:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:05:44,788:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:05:44,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:05:44,897:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:05:44,899:INFO:setup() successfully completed in 1.72s...............
2025-11-11 23:05:44,900:INFO:Initializing compare_models()
2025-11-11 23:05:44,900:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>, include=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>, 'include': None, 'exclude': ['ridge', 'dummy', 'svm', 'quadratic_discriminant_analysis'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['ridge', 'dummy', 'svm', 'quadratic_discriminant_analysis'])
2025-11-11 23:05:44,900:INFO:Checking exceptions
2025-11-11 23:05:44,913:INFO:Preparing display monitor
2025-11-11 23:05:44,924:INFO:Initializing Logistic Regression
2025-11-11 23:05:44,924:INFO:Total runtime is 0.0 minutes
2025-11-11 23:05:44,924:INFO:SubProcess create_model() called ==================================
2025-11-11 23:05:44,924:INFO:Initializing create_model()
2025-11-11 23:05:44,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016EDACA0940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:05:44,924:INFO:Checking exceptions
2025-11-11 23:05:44,924:INFO:Importing libraries
2025-11-11 23:05:44,924:INFO:Copying training dataset
2025-11-11 23:05:44,942:INFO:Defining folds
2025-11-11 23:05:44,943:INFO:Declaring metric variables
2025-11-11 23:05:44,943:INFO:Importing untrained model
2025-11-11 23:05:44,943:INFO:Logistic Regression Imported successfully
2025-11-11 23:05:44,943:INFO:Starting cross validation
2025-11-11 23:05:44,947:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:05:48,140:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:05:48,190:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:05:48,494:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:05:48,526:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:05:48,563:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:05:48,587:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:05:48,627:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:05:48,636:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:05:48,654:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:05:48,658:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:05:49,059:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:05:49,206:INFO:Calculating mean and std
2025-11-11 23:05:49,210:INFO:Creating metrics dataframe
2025-11-11 23:05:49,214:INFO:Uploading results into container
2025-11-11 23:05:49,215:INFO:Uploading model into container now
2025-11-11 23:05:49,215:INFO:_master_model_container: 1
2025-11-11 23:05:49,215:INFO:_display_container: 2
2025-11-11 23:05:49,215:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-11 23:05:49,215:INFO:create_model() successfully completed......................................
2025-11-11 23:05:49,406:INFO:SubProcess create_model() end ==================================
2025-11-11 23:05:49,406:INFO:Creating metrics dataframe
2025-11-11 23:05:49,412:INFO:Initializing K Neighbors Classifier
2025-11-11 23:05:49,412:INFO:Total runtime is 0.07479956944783529 minutes
2025-11-11 23:05:49,412:INFO:SubProcess create_model() called ==================================
2025-11-11 23:05:49,412:INFO:Initializing create_model()
2025-11-11 23:05:49,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016EDACA0940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:05:49,413:INFO:Checking exceptions
2025-11-11 23:05:49,413:INFO:Importing libraries
2025-11-11 23:05:49,413:INFO:Copying training dataset
2025-11-11 23:05:49,433:INFO:Defining folds
2025-11-11 23:05:49,435:INFO:Declaring metric variables
2025-11-11 23:05:49,435:INFO:Importing untrained model
2025-11-11 23:05:49,435:INFO:K Neighbors Classifier Imported successfully
2025-11-11 23:05:49,435:INFO:Starting cross validation
2025-11-11 23:05:49,439:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:05:52,569:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:05:52,612:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:05:52,663:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:05:52,669:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:05:52,692:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:05:52,754:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:05:53,687:INFO:Calculating mean and std
2025-11-11 23:05:53,691:INFO:Creating metrics dataframe
2025-11-11 23:05:53,694:INFO:Uploading results into container
2025-11-11 23:05:53,696:INFO:Uploading model into container now
2025-11-11 23:05:53,696:INFO:_master_model_container: 2
2025-11-11 23:05:53,696:INFO:_display_container: 2
2025-11-11 23:05:53,696:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-11 23:05:53,696:INFO:create_model() successfully completed......................................
2025-11-11 23:05:53,826:INFO:SubProcess create_model() end ==================================
2025-11-11 23:05:53,826:INFO:Creating metrics dataframe
2025-11-11 23:05:53,831:INFO:Initializing Naive Bayes
2025-11-11 23:05:53,831:INFO:Total runtime is 0.14845517079035442 minutes
2025-11-11 23:05:53,831:INFO:SubProcess create_model() called ==================================
2025-11-11 23:05:53,833:INFO:Initializing create_model()
2025-11-11 23:05:53,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016EDACA0940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:05:53,833:INFO:Checking exceptions
2025-11-11 23:05:53,833:INFO:Importing libraries
2025-11-11 23:05:53,833:INFO:Copying training dataset
2025-11-11 23:05:53,853:INFO:Defining folds
2025-11-11 23:05:53,854:INFO:Declaring metric variables
2025-11-11 23:05:53,854:INFO:Importing untrained model
2025-11-11 23:05:53,854:INFO:Naive Bayes Imported successfully
2025-11-11 23:05:53,855:INFO:Starting cross validation
2025-11-11 23:05:53,860:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:05:54,183:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:05:54,195:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:05:54,219:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:05:54,225:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:05:54,234:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:05:54,247:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:05:54,254:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:05:54,255:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:05:54,275:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:05:54,293:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:05:54,311:INFO:Calculating mean and std
2025-11-11 23:05:54,313:INFO:Creating metrics dataframe
2025-11-11 23:05:54,319:INFO:Uploading results into container
2025-11-11 23:05:54,319:INFO:Uploading model into container now
2025-11-11 23:05:54,320:INFO:_master_model_container: 3
2025-11-11 23:05:54,321:INFO:_display_container: 2
2025-11-11 23:05:54,321:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-11 23:05:54,321:INFO:create_model() successfully completed......................................
2025-11-11 23:05:54,491:INFO:SubProcess create_model() end ==================================
2025-11-11 23:05:54,493:INFO:Creating metrics dataframe
2025-11-11 23:05:54,499:INFO:Initializing Decision Tree Classifier
2025-11-11 23:05:54,499:INFO:Total runtime is 0.15959069331487022 minutes
2025-11-11 23:05:54,500:INFO:SubProcess create_model() called ==================================
2025-11-11 23:05:54,500:INFO:Initializing create_model()
2025-11-11 23:05:54,500:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016EDACA0940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:05:54,500:INFO:Checking exceptions
2025-11-11 23:05:54,500:INFO:Importing libraries
2025-11-11 23:05:54,500:INFO:Copying training dataset
2025-11-11 23:05:54,523:INFO:Defining folds
2025-11-11 23:05:54,523:INFO:Declaring metric variables
2025-11-11 23:05:54,523:INFO:Importing untrained model
2025-11-11 23:05:54,523:INFO:Decision Tree Classifier Imported successfully
2025-11-11 23:05:54,525:INFO:Starting cross validation
2025-11-11 23:05:54,529:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:05:55,024:INFO:Calculating mean and std
2025-11-11 23:05:55,027:INFO:Creating metrics dataframe
2025-11-11 23:05:55,031:INFO:Uploading results into container
2025-11-11 23:05:55,033:INFO:Uploading model into container now
2025-11-11 23:05:55,034:INFO:_master_model_container: 4
2025-11-11 23:05:55,034:INFO:_display_container: 2
2025-11-11 23:05:55,035:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-11-11 23:05:55,035:INFO:create_model() successfully completed......................................
2025-11-11 23:05:55,203:INFO:SubProcess create_model() end ==================================
2025-11-11 23:05:55,203:INFO:Creating metrics dataframe
2025-11-11 23:05:55,210:INFO:Initializing Random Forest Classifier
2025-11-11 23:05:55,210:INFO:Total runtime is 0.17144188483556114 minutes
2025-11-11 23:05:55,212:INFO:SubProcess create_model() called ==================================
2025-11-11 23:05:55,212:INFO:Initializing create_model()
2025-11-11 23:05:55,212:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016EDACA0940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:05:55,212:INFO:Checking exceptions
2025-11-11 23:05:55,213:INFO:Importing libraries
2025-11-11 23:05:55,213:INFO:Copying training dataset
2025-11-11 23:05:55,232:INFO:Defining folds
2025-11-11 23:05:55,232:INFO:Declaring metric variables
2025-11-11 23:05:55,232:INFO:Importing untrained model
2025-11-11 23:05:55,234:INFO:Random Forest Classifier Imported successfully
2025-11-11 23:05:55,235:INFO:Starting cross validation
2025-11-11 23:05:55,239:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:05:57,310:INFO:Calculating mean and std
2025-11-11 23:05:57,315:INFO:Creating metrics dataframe
2025-11-11 23:05:57,320:INFO:Uploading results into container
2025-11-11 23:05:57,320:INFO:Uploading model into container now
2025-11-11 23:05:57,322:INFO:_master_model_container: 5
2025-11-11 23:05:57,322:INFO:_display_container: 2
2025-11-11 23:05:57,322:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-11-11 23:05:57,322:INFO:create_model() successfully completed......................................
2025-11-11 23:05:57,469:INFO:SubProcess create_model() end ==================================
2025-11-11 23:05:57,469:INFO:Creating metrics dataframe
2025-11-11 23:05:57,475:INFO:Initializing Quadratic Discriminant Analysis
2025-11-11 23:05:57,475:INFO:Total runtime is 0.20919716755549114 minutes
2025-11-11 23:05:57,475:INFO:SubProcess create_model() called ==================================
2025-11-11 23:05:57,475:INFO:Initializing create_model()
2025-11-11 23:05:57,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016EDACA0940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:05:57,475:INFO:Checking exceptions
2025-11-11 23:05:57,475:INFO:Importing libraries
2025-11-11 23:05:57,475:INFO:Copying training dataset
2025-11-11 23:05:57,497:INFO:Defining folds
2025-11-11 23:05:57,498:INFO:Declaring metric variables
2025-11-11 23:05:57,498:INFO:Importing untrained model
2025-11-11 23:05:57,498:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-11 23:05:57,498:INFO:Starting cross validation
2025-11-11 23:05:57,502:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:05:57,763:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:05:57,775:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:05:57,781:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:05:57,782:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:05:57,802:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:05:57,802:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:05:57,811:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:05:57,812:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:05:57,813:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:05:57,817:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:05:57,958:INFO:Calculating mean and std
2025-11-11 23:05:57,964:INFO:Creating metrics dataframe
2025-11-11 23:05:57,970:INFO:Uploading results into container
2025-11-11 23:05:57,973:INFO:Uploading model into container now
2025-11-11 23:05:57,974:INFO:_master_model_container: 6
2025-11-11 23:05:57,974:INFO:_display_container: 2
2025-11-11 23:05:57,974:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-11 23:05:57,974:INFO:create_model() successfully completed......................................
2025-11-11 23:05:58,134:INFO:SubProcess create_model() end ==================================
2025-11-11 23:05:58,135:INFO:Creating metrics dataframe
2025-11-11 23:05:58,142:INFO:Initializing Ada Boost Classifier
2025-11-11 23:05:58,142:INFO:Total runtime is 0.22031381527582805 minutes
2025-11-11 23:05:58,144:INFO:SubProcess create_model() called ==================================
2025-11-11 23:05:58,145:INFO:Initializing create_model()
2025-11-11 23:05:58,145:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016EDACA0940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:05:58,145:INFO:Checking exceptions
2025-11-11 23:05:58,145:INFO:Importing libraries
2025-11-11 23:05:58,145:INFO:Copying training dataset
2025-11-11 23:05:58,164:INFO:Defining folds
2025-11-11 23:05:58,164:INFO:Declaring metric variables
2025-11-11 23:05:58,165:INFO:Importing untrained model
2025-11-11 23:05:58,165:INFO:Ada Boost Classifier Imported successfully
2025-11-11 23:05:58,166:INFO:Starting cross validation
2025-11-11 23:05:58,169:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:05:58,406:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:05:58,409:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:05:58,410:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:05:58,412:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:05:58,419:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:05:58,421:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:05:58,422:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:05:58,426:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:05:58,431:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:05:58,441:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:05:59,372:INFO:Calculating mean and std
2025-11-11 23:05:59,376:INFO:Creating metrics dataframe
2025-11-11 23:05:59,378:INFO:Uploading results into container
2025-11-11 23:05:59,381:INFO:Uploading model into container now
2025-11-11 23:05:59,381:INFO:_master_model_container: 7
2025-11-11 23:05:59,381:INFO:_display_container: 2
2025-11-11 23:05:59,382:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-11-11 23:05:59,383:INFO:create_model() successfully completed......................................
2025-11-11 23:05:59,537:INFO:SubProcess create_model() end ==================================
2025-11-11 23:05:59,538:INFO:Creating metrics dataframe
2025-11-11 23:05:59,543:INFO:Initializing Gradient Boosting Classifier
2025-11-11 23:05:59,543:INFO:Total runtime is 0.24365965922673544 minutes
2025-11-11 23:05:59,543:INFO:SubProcess create_model() called ==================================
2025-11-11 23:05:59,543:INFO:Initializing create_model()
2025-11-11 23:05:59,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016EDACA0940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:05:59,543:INFO:Checking exceptions
2025-11-11 23:05:59,543:INFO:Importing libraries
2025-11-11 23:05:59,545:INFO:Copying training dataset
2025-11-11 23:05:59,562:INFO:Defining folds
2025-11-11 23:05:59,562:INFO:Declaring metric variables
2025-11-11 23:05:59,563:INFO:Importing untrained model
2025-11-11 23:05:59,564:INFO:Gradient Boosting Classifier Imported successfully
2025-11-11 23:05:59,564:INFO:Starting cross validation
2025-11-11 23:05:59,569:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:06:03,163:INFO:Calculating mean and std
2025-11-11 23:06:03,166:INFO:Creating metrics dataframe
2025-11-11 23:06:03,172:INFO:Uploading results into container
2025-11-11 23:06:03,172:INFO:Uploading model into container now
2025-11-11 23:06:03,174:INFO:_master_model_container: 8
2025-11-11 23:06:03,175:INFO:_display_container: 2
2025-11-11 23:06:03,176:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-11 23:06:03,176:INFO:create_model() successfully completed......................................
2025-11-11 23:06:03,327:INFO:SubProcess create_model() end ==================================
2025-11-11 23:06:03,328:INFO:Creating metrics dataframe
2025-11-11 23:06:03,333:INFO:Initializing Linear Discriminant Analysis
2025-11-11 23:06:03,333:INFO:Total runtime is 0.3068263093630473 minutes
2025-11-11 23:06:03,334:INFO:SubProcess create_model() called ==================================
2025-11-11 23:06:03,335:INFO:Initializing create_model()
2025-11-11 23:06:03,335:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016EDACA0940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:06:03,335:INFO:Checking exceptions
2025-11-11 23:06:03,335:INFO:Importing libraries
2025-11-11 23:06:03,335:INFO:Copying training dataset
2025-11-11 23:06:03,356:INFO:Defining folds
2025-11-11 23:06:03,357:INFO:Declaring metric variables
2025-11-11 23:06:03,357:INFO:Importing untrained model
2025-11-11 23:06:03,357:INFO:Linear Discriminant Analysis Imported successfully
2025-11-11 23:06:03,358:INFO:Starting cross validation
2025-11-11 23:06:03,364:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:06:03,763:INFO:Calculating mean and std
2025-11-11 23:06:03,767:INFO:Creating metrics dataframe
2025-11-11 23:06:03,771:INFO:Uploading results into container
2025-11-11 23:06:03,772:INFO:Uploading model into container now
2025-11-11 23:06:03,773:INFO:_master_model_container: 9
2025-11-11 23:06:03,773:INFO:_display_container: 2
2025-11-11 23:06:03,774:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-11 23:06:03,774:INFO:create_model() successfully completed......................................
2025-11-11 23:06:03,935:INFO:SubProcess create_model() end ==================================
2025-11-11 23:06:03,935:INFO:Creating metrics dataframe
2025-11-11 23:06:03,942:INFO:Initializing Extra Trees Classifier
2025-11-11 23:06:03,942:INFO:Total runtime is 0.31696924368540447 minutes
2025-11-11 23:06:03,942:INFO:SubProcess create_model() called ==================================
2025-11-11 23:06:03,943:INFO:Initializing create_model()
2025-11-11 23:06:03,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016EDACA0940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:06:03,943:INFO:Checking exceptions
2025-11-11 23:06:03,943:INFO:Importing libraries
2025-11-11 23:06:03,943:INFO:Copying training dataset
2025-11-11 23:06:03,961:INFO:Defining folds
2025-11-11 23:06:03,961:INFO:Declaring metric variables
2025-11-11 23:06:03,961:INFO:Importing untrained model
2025-11-11 23:06:03,963:INFO:Extra Trees Classifier Imported successfully
2025-11-11 23:06:03,963:INFO:Starting cross validation
2025-11-11 23:06:03,969:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:06:05,598:INFO:Calculating mean and std
2025-11-11 23:06:05,601:INFO:Creating metrics dataframe
2025-11-11 23:06:05,607:INFO:Uploading results into container
2025-11-11 23:06:05,607:INFO:Uploading model into container now
2025-11-11 23:06:05,609:INFO:_master_model_container: 10
2025-11-11 23:06:05,609:INFO:_display_container: 2
2025-11-11 23:06:05,610:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-11-11 23:06:05,610:INFO:create_model() successfully completed......................................
2025-11-11 23:06:05,753:INFO:SubProcess create_model() end ==================================
2025-11-11 23:06:05,753:INFO:Creating metrics dataframe
2025-11-11 23:06:05,758:INFO:Initializing Light Gradient Boosting Machine
2025-11-11 23:06:05,759:INFO:Total runtime is 0.3472367286682129 minutes
2025-11-11 23:06:05,759:INFO:SubProcess create_model() called ==================================
2025-11-11 23:06:05,759:INFO:Initializing create_model()
2025-11-11 23:06:05,760:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016EDACA0940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:06:05,760:INFO:Checking exceptions
2025-11-11 23:06:05,760:INFO:Importing libraries
2025-11-11 23:06:05,760:INFO:Copying training dataset
2025-11-11 23:06:05,779:INFO:Defining folds
2025-11-11 23:06:05,779:INFO:Declaring metric variables
2025-11-11 23:06:05,779:INFO:Importing untrained model
2025-11-11 23:06:05,782:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-11 23:06:05,783:INFO:Starting cross validation
2025-11-11 23:06:05,787:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:06:28,057:INFO:Calculating mean and std
2025-11-11 23:06:28,062:INFO:Creating metrics dataframe
2025-11-11 23:06:28,068:INFO:Uploading results into container
2025-11-11 23:06:28,068:INFO:Uploading model into container now
2025-11-11 23:06:28,070:INFO:_master_model_container: 11
2025-11-11 23:06:28,070:INFO:_display_container: 2
2025-11-11 23:06:28,070:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-11 23:06:28,071:INFO:create_model() successfully completed......................................
2025-11-11 23:06:28,215:INFO:SubProcess create_model() end ==================================
2025-11-11 23:06:28,215:INFO:Creating metrics dataframe
2025-11-11 23:06:28,221:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-11-11 23:06:28,226:INFO:Initializing create_model()
2025-11-11 23:06:28,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:06:28,226:INFO:Checking exceptions
2025-11-11 23:06:28,228:INFO:Importing libraries
2025-11-11 23:06:28,228:INFO:Copying training dataset
2025-11-11 23:06:28,246:INFO:Defining folds
2025-11-11 23:06:28,246:INFO:Declaring metric variables
2025-11-11 23:06:28,246:INFO:Importing untrained model
2025-11-11 23:06:28,246:INFO:Declaring custom model
2025-11-11 23:06:28,248:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-11 23:06:28,253:INFO:Cross validation set to False
2025-11-11 23:06:28,253:INFO:Fitting Model
2025-11-11 23:06:28,480:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-11 23:06:28,481:INFO:[LightGBM] [Info] Number of positive: 1139, number of negative: 5949
2025-11-11 23:06:28,487:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003474 seconds.
2025-11-11 23:06:28,487:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-11-11 23:06:28,487:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-11-11 23:06:28,488:INFO:[LightGBM] [Info] Total Bins 2320
2025-11-11 23:06:28,489:INFO:[LightGBM] [Info] Number of data points in the train set: 7088, number of used features: 36
2025-11-11 23:06:28,490:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160694 -> initscore=-1.653072
2025-11-11 23:06:28,490:INFO:[LightGBM] [Info] Start training from score -1.653072
2025-11-11 23:06:29,872:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-11 23:06:29,872:INFO:create_model() successfully completed......................................
2025-11-11 23:06:30,008:INFO:_master_model_container: 11
2025-11-11 23:06:30,010:INFO:_display_container: 2
2025-11-11 23:06:30,011:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-11 23:06:30,011:INFO:compare_models() successfully completed......................................
2025-11-11 23:06:30,033:INFO:Initializing tune_model()
2025-11-11 23:06:30,034:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=30, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>)
2025-11-11 23:06:30,034:INFO:Checking exceptions
2025-11-11 23:06:30,046:INFO:Copying training dataset
2025-11-11 23:06:30,057:INFO:Checking base model
2025-11-11 23:06:30,058:INFO:Base model : Light Gradient Boosting Machine
2025-11-11 23:06:30,059:INFO:Declaring metric variables
2025-11-11 23:06:30,059:INFO:Defining Hyperparameters
2025-11-11 23:06:30,233:INFO:Tuning with n_jobs=-1
2025-11-11 23:06:30,233:INFO:Initializing RandomizedSearchCV
2025-11-11 23:13:28,524:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.2, 'actual_estimator__num_leaves': 40, 'actual_estimator__n_estimators': 160, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.4}
2025-11-11 23:13:28,529:INFO:Hyperparameter search completed
2025-11-11 23:13:28,529:INFO:SubProcess create_model() called ==================================
2025-11-11 23:13:28,531:INFO:Initializing create_model()
2025-11-11 23:13:28,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016ED79E97F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.2, 'num_leaves': 40, 'n_estimators': 160, 'min_split_gain': 0.4, 'min_child_samples': 6, 'learning_rate': 0.1, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.4})
2025-11-11 23:13:28,531:INFO:Checking exceptions
2025-11-11 23:13:28,533:INFO:Importing libraries
2025-11-11 23:13:28,533:INFO:Copying training dataset
2025-11-11 23:13:28,556:INFO:Defining folds
2025-11-11 23:13:28,556:INFO:Declaring metric variables
2025-11-11 23:13:28,557:INFO:Importing untrained model
2025-11-11 23:13:28,557:INFO:Declaring custom model
2025-11-11 23:13:28,561:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-11 23:13:28,561:INFO:Starting cross validation
2025-11-11 23:13:28,565:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:13:56,799:INFO:Calculating mean and std
2025-11-11 23:13:56,803:INFO:Creating metrics dataframe
2025-11-11 23:13:56,808:INFO:Finalizing model
2025-11-11 23:13:57,011:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-11 23:13:57,011:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-11 23:13:57,011:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-11 23:13:57,026:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-11 23:13:57,027:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-11 23:13:57,027:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-11 23:13:57,027:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-11 23:13:57,029:INFO:[LightGBM] [Info] Number of positive: 1139, number of negative: 5949
2025-11-11 23:13:57,035:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003490 seconds.
2025-11-11 23:13:57,035:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-11 23:13:57,035:INFO:[LightGBM] [Info] Total Bins 2322
2025-11-11 23:13:57,036:INFO:[LightGBM] [Info] Number of data points in the train set: 7088, number of used features: 37
2025-11-11 23:13:57,037:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160694 -> initscore=-1.653072
2025-11-11 23:13:57,038:INFO:[LightGBM] [Info] Start training from score -1.653072
2025-11-11 23:13:58,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:58,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:58,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:58,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:58,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:58,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:58,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:58,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:58,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:58,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:58,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:58,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:58,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:58,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:58,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:58,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:58,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:58,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:58,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:13:59,960:INFO:Uploading results into container
2025-11-11 23:13:59,962:INFO:Uploading model into container now
2025-11-11 23:13:59,963:INFO:_master_model_container: 12
2025-11-11 23:13:59,963:INFO:_display_container: 3
2025-11-11 23:13:59,965:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-11 23:13:59,965:INFO:create_model() successfully completed......................................
2025-11-11 23:14:00,207:INFO:SubProcess create_model() end ==================================
2025-11-11 23:14:00,209:INFO:choose_better activated
2025-11-11 23:14:00,209:INFO:SubProcess create_model() called ==================================
2025-11-11 23:14:00,211:INFO:Initializing create_model()
2025-11-11 23:14:00,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:14:00,211:INFO:Checking exceptions
2025-11-11 23:14:00,211:INFO:Importing libraries
2025-11-11 23:14:00,213:INFO:Copying training dataset
2025-11-11 23:14:00,234:INFO:Defining folds
2025-11-11 23:14:00,234:INFO:Declaring metric variables
2025-11-11 23:14:00,234:INFO:Importing untrained model
2025-11-11 23:14:00,234:INFO:Declaring custom model
2025-11-11 23:14:00,237:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-11 23:14:00,237:INFO:Starting cross validation
2025-11-11 23:14:00,241:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:14:24,718:INFO:Calculating mean and std
2025-11-11 23:14:24,720:INFO:Creating metrics dataframe
2025-11-11 23:14:24,723:INFO:Finalizing model
2025-11-11 23:14:24,930:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-11 23:14:24,932:INFO:[LightGBM] [Info] Number of positive: 1139, number of negative: 5949
2025-11-11 23:14:24,937:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002789 seconds.
2025-11-11 23:14:24,937:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-11-11 23:14:24,937:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-11-11 23:14:24,938:INFO:[LightGBM] [Info] Total Bins 2320
2025-11-11 23:14:24,939:INFO:[LightGBM] [Info] Number of data points in the train set: 7088, number of used features: 36
2025-11-11 23:14:24,939:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160694 -> initscore=-1.653072
2025-11-11 23:14:24,940:INFO:[LightGBM] [Info] Start training from score -1.653072
2025-11-11 23:14:26,267:INFO:Uploading results into container
2025-11-11 23:14:26,269:INFO:Uploading model into container now
2025-11-11 23:14:26,269:INFO:_master_model_container: 13
2025-11-11 23:14:26,269:INFO:_display_container: 4
2025-11-11 23:14:26,271:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-11 23:14:26,271:INFO:create_model() successfully completed......................................
2025-11-11 23:14:26,435:INFO:SubProcess create_model() end ==================================
2025-11-11 23:14:26,438:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8911
2025-11-11 23:14:26,438:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.892
2025-11-11 23:14:26,441:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-11-11 23:14:26,441:INFO:choose_better completed
2025-11-11 23:14:26,447:INFO:_master_model_container: 13
2025-11-11 23:14:26,449:INFO:_display_container: 3
2025-11-11 23:14:26,449:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-11 23:14:26,449:INFO:tune_model() successfully completed......................................
2025-11-11 23:14:26,597:INFO:Initializing finalize_model()
2025-11-11 23:14:26,598:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>, estimator=LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-11-11 23:14:26,599:INFO:Finalizing LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-11 23:14:26,609:INFO:Initializing create_model()
2025-11-11 23:14:26,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016ED781D4C0>, estimator=LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:14:26,610:INFO:Checking exceptions
2025-11-11 23:14:26,610:INFO:Importing libraries
2025-11-11 23:14:26,610:INFO:Copying training dataset
2025-11-11 23:14:26,612:INFO:Defining folds
2025-11-11 23:14:26,612:INFO:Declaring metric variables
2025-11-11 23:14:26,612:INFO:Importing untrained model
2025-11-11 23:14:26,612:INFO:Declaring custom model
2025-11-11 23:14:26,614:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-11 23:14:26,617:INFO:Cross validation set to False
2025-11-11 23:14:26,617:INFO:Fitting Model
2025-11-11 23:14:26,849:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-11 23:14:26,849:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-11 23:14:26,849:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-11 23:14:26,869:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-11 23:14:26,872:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-11 23:14:26,873:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-11 23:14:26,873:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-11 23:14:26,874:INFO:[LightGBM] [Info] Number of positive: 1627, number of negative: 8500
2025-11-11 23:14:26,880:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003465 seconds.
2025-11-11 23:14:26,880:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-11 23:14:26,881:INFO:[LightGBM] [Info] Total Bins 2324
2025-11-11 23:14:26,882:INFO:[LightGBM] [Info] Number of data points in the train set: 10127, number of used features: 37
2025-11-11 23:14:26,885:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160660 -> initscore=-1.653328
2025-11-11 23:14:26,885:INFO:[LightGBM] [Info] Start training from score -1.653328
2025-11-11 23:14:28,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:14:28,789:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-11 23:14:28,789:INFO:create_model() successfully completed......................................
2025-11-11 23:14:28,941:INFO:_master_model_container: 13
2025-11-11 23:14:28,941:INFO:_display_container: 3
2025-11-11 23:14:28,978:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-11 23:14:28,980:INFO:finalize_model() successfully completed......................................
2025-11-11 23:14:29,164:INFO:Initializing save_model()
2025-11-11 23:14:29,165:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=pycaret_best_automl_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\usuario\AppData\Local\Temp\2\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['education_level',
                                             'marital_status',
                                             'income_category',
                                             'card_category'],
                                    transformer=OneHotEncoder(cols=['education_level',
                                                                    'marital_status',
                                                                    'income_category',
                                                                    'card_category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-11-11 23:14:29,165:INFO:Adding model into prep_pipe
2025-11-11 23:14:29,166:WARNING:Only Model saved as it was a pipeline.
2025-11-11 23:14:29,201:INFO:pycaret_best_automl_model.pkl saved in current working directory
2025-11-11 23:14:29,242:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-11 23:14:29,242:INFO:save_model() successfully completed......................................
2025-11-11 23:14:29,384:INFO:Initializing load_model()
2025-11-11 23:14:29,384:INFO:load_model(model_name=pycaret_best_automl_model, platform=None, authentication=None, verbose=False)
2025-11-11 23:21:21,349:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_0b99bfdc393a462cb7d46468acaf8cdc
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,350:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_46fcce98304649908b2b1112fc4f29ff_c79b91dbfe624acbbd07e18ed273e61d
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,350:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_630ccba500024736992aba639719ec4c
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,350:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_241151fca630478fbe8708c7f8c873f2_bc942eaa2d404d1586cf3293fe3de6dc
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,351:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_6c5d08f155bf4dd58ea82532b6784124
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,351:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_4533491b2d384672826a128e9aa31ead_cec30e6497de4569a35c522845fed792
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,351:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_342763a2adf94a13ab0807af1ab0d1f0
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,351:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_76384c4a269e4d4ea58514690c944e08_43d331004e7447a1a711fb519c259d00
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,351:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_006d8fb3dcb0428a89233e74890e1338
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,353:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_5b3f7f77b4194da088a6fec2c23f30c0_6d05405587a3423da290c91361e79bd6
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,353:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_0bd1e39298b44378a1e677fe78bbd6b2
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,353:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_219be34027c5482ab27181d4e19fc405_b9aa194cc88d41598f80dc53bc530da0
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,353:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_3344f487bc68492ca8825c7db725fad5
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,353:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_812f0ed6156542d48f8fcd587283a0be_2a084c86ef364484a6524469a1c9dc21
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,354:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_7736d5b1599243abb4a9146302935adf
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,354:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_0a17ec7a10f64865971a845307abedb3_c850d731907a4d158eb8e5492c312e4f
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,355:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_f2e0904f8e074df6a2938a4f98170f4e
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,355:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_6b3f4ce8ae314d4f9171929c4cad71a1_0a5167cccfe44daa82f84f5aeebf8bfe
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,355:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_474a37ab1b01428da419f081903513c4
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,355:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_a82b7f6abde849f9b91f5c69550a4f7e_5bf5f892e02c46479216a9538efc4619
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,355:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_583ba266a61e4465990e07428a70abb3
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,355:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_108122156bac4e54bb8278b3a3091b0f_36e6095a373340ab84123acb76711012
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,357:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_c4f284d3d4fe4a82b14b12cf2c6d9cb7
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,357:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_0233b6f3a7a8460197cd520268bbbb19_91c3f0c37a5b4e37a5edd049fa9b5a52
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,357:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_aa9f81d4e4d64be1b939c3460f6058dc
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,357:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_69aae9b9ca0044de91e77a25eb514551_f1342f3042ef44af977d444ef4745133
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,357:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_48b04179628e4b418eef931e277c9a7c
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,358:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_652d41d913bf47559040b6df31cf87b5_28060335d51244449dc982896041b900
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,359:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_7545a4fdb39c45a3968987f631c7497e
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,360:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_451f0ecb430740d8906739b52955f6d8_20236b910a6246d8b021e450684dd9d2
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,360:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_e98b04183ec84a69bd6ccade154c5c3f
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,360:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_5fbab084a98c41e38e9b3576a9c423e9_9f71f65448fa4b4f9a18e4b26d148b1e
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,360:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_3672acce4b6b44f09c9f1c44b424fd7b
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,361:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_3670e38cad7f46e2b8a3f9d6868a6167_bb736e7c76974c4681c1a04a4ed4a53a
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,361:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_b425f76aebf94b789648dbc3d4805d7f
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,362:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_db6c075e67644b8a893d4a6520fabe0b_dc91d115d8f547a994f11375df51b6e7
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,363:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_c58e188c237348b59bb45bf629debd91
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:21,363:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\usuario\AppData\Local\Temp\2\joblib_memmapping_folder_12184_56db34fc12ef40adbe3658893a0c21d9_0a4c76fe1ba041b6a585d6881edece40
  warnings.warn("Failed to delete temporary folder: {}"

2025-11-11 23:21:32,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 23:21:32,506:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 23:21:32,506:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 23:21:32,506:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 23:24:14,889:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 23:24:14,889:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 23:24:14,889:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 23:24:14,889:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 23:30:44,431:INFO:PyCaret ClassificationExperiment
2025-11-11 23:30:44,432:INFO:Logging name: clf-default-name
2025-11-11 23:30:44,432:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-11 23:30:44,432:INFO:version 3.3.2
2025-11-11 23:30:44,432:INFO:Initializing setup()
2025-11-11 23:30:44,432:INFO:self.USI: 5622
2025-11-11 23:30:44,432:INFO:self._variable_keys: {'fold_shuffle_param', 'data', 'pipeline', 'seed', 'is_multiclass', 'X_train', 'USI', 'exp_name_log', 'X_test', 'log_plots_param', 'html_param', 'y_train', 'target_param', 'X', 'logging_param', 'fix_imbalance', 'fold_generator', 'idx', '_available_plots', 'n_jobs_param', '_ml_usecase', 'gpu_n_jobs_param', 'gpu_param', 'y_test', 'memory', 'exp_id', 'fold_groups_param', 'y'}
2025-11-11 23:30:44,432:INFO:Checking environment
2025-11-11 23:30:44,432:INFO:python_version: 3.9.10
2025-11-11 23:30:44,432:INFO:python_build: ('tags/v3.9.10:f2f3f53', 'Jan 17 2022 15:14:21')
2025-11-11 23:30:44,432:INFO:machine: AMD64
2025-11-11 23:30:44,433:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-11 23:30:44,438:INFO:Memory: svmem(total=42001428480, available=28072804352, percent=33.2, used=13928624128, free=28072804352)
2025-11-11 23:30:44,438:INFO:Physical Core: 16
2025-11-11 23:30:44,438:INFO:Logical Core: 16
2025-11-11 23:30:44,438:INFO:Checking libraries
2025-11-11 23:30:44,438:INFO:System:
2025-11-11 23:30:44,438:INFO:    python: 3.9.10 (tags/v3.9.10:f2f3f53, Jan 17 2022, 15:14:21) [MSC v.1929 64 bit (AMD64)]
2025-11-11 23:30:44,438:INFO:executable: C:\Users\usuario\PycharmProjects\PythonProject\.venv\Scripts\python.exe
2025-11-11 23:30:44,438:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-11 23:30:44,438:INFO:PyCaret required dependencies:
2025-11-11 23:30:44,539:INFO:                 pip: 25.3
2025-11-11 23:30:44,539:INFO:          setuptools: 80.3.1
2025-11-11 23:30:44,539:INFO:             pycaret: 3.3.2
2025-11-11 23:30:44,539:INFO:             IPython: 8.18.1
2025-11-11 23:30:44,539:INFO:          ipywidgets: 8.1.8
2025-11-11 23:30:44,539:INFO:                tqdm: 4.67.1
2025-11-11 23:30:44,539:INFO:               numpy: 1.26.4
2025-11-11 23:30:44,539:INFO:              pandas: 2.1.4
2025-11-11 23:30:44,539:INFO:              jinja2: 3.1.6
2025-11-11 23:30:44,540:INFO:               scipy: 1.11.4
2025-11-11 23:30:44,540:INFO:              joblib: 1.3.2
2025-11-11 23:30:44,540:INFO:             sklearn: 1.4.2
2025-11-11 23:30:44,540:INFO:                pyod: 2.0.5
2025-11-11 23:30:44,540:INFO:            imblearn: 0.12.4
2025-11-11 23:30:44,540:INFO:   category_encoders: 2.6.4
2025-11-11 23:30:44,540:INFO:            lightgbm: 4.6.0
2025-11-11 23:30:44,540:INFO:               numba: 0.60.0
2025-11-11 23:30:44,540:INFO:            requests: 2.32.5
2025-11-11 23:30:44,541:INFO:          matplotlib: 3.7.5
2025-11-11 23:30:44,541:INFO:          scikitplot: 0.3.7
2025-11-11 23:30:44,541:INFO:         yellowbrick: 1.5
2025-11-11 23:30:44,541:INFO:              plotly: 6.4.0
2025-11-11 23:30:44,541:INFO:    plotly-resampler: Not installed
2025-11-11 23:30:44,541:INFO:             kaleido: 1.2.0
2025-11-11 23:30:44,541:INFO:           schemdraw: 0.15
2025-11-11 23:30:44,541:INFO:         statsmodels: 0.14.5
2025-11-11 23:30:44,541:INFO:              sktime: 0.26.0
2025-11-11 23:30:44,541:INFO:               tbats: 1.1.3
2025-11-11 23:30:44,543:INFO:            pmdarima: 2.0.4
2025-11-11 23:30:44,544:INFO:              psutil: 7.1.3
2025-11-11 23:30:44,544:INFO:          markupsafe: 3.0.3
2025-11-11 23:30:44,544:INFO:             pickle5: Not installed
2025-11-11 23:30:44,544:INFO:         cloudpickle: 3.1.2
2025-11-11 23:30:44,544:INFO:         deprecation: 2.1.0
2025-11-11 23:30:44,544:INFO:              xxhash: 3.6.0
2025-11-11 23:30:44,544:INFO:           wurlitzer: Not installed
2025-11-11 23:30:44,544:INFO:PyCaret optional dependencies:
2025-11-11 23:30:44,636:INFO:                shap: Not installed
2025-11-11 23:30:44,636:INFO:           interpret: Not installed
2025-11-11 23:30:44,636:INFO:                umap: Not installed
2025-11-11 23:30:44,636:INFO:     ydata_profiling: Not installed
2025-11-11 23:30:44,636:INFO:  explainerdashboard: Not installed
2025-11-11 23:30:44,636:INFO:             autoviz: Not installed
2025-11-11 23:30:44,636:INFO:           fairlearn: Not installed
2025-11-11 23:30:44,636:INFO:          deepchecks: Not installed
2025-11-11 23:30:44,636:INFO:             xgboost: Not installed
2025-11-11 23:30:44,636:INFO:            catboost: Not installed
2025-11-11 23:30:44,636:INFO:              kmodes: Not installed
2025-11-11 23:30:44,636:INFO:             mlxtend: Not installed
2025-11-11 23:30:44,636:INFO:       statsforecast: Not installed
2025-11-11 23:30:44,636:INFO:        tune_sklearn: Not installed
2025-11-11 23:30:44,636:INFO:                 ray: Not installed
2025-11-11 23:30:44,636:INFO:            hyperopt: Not installed
2025-11-11 23:30:44,637:INFO:              optuna: Not installed
2025-11-11 23:30:44,637:INFO:               skopt: Not installed
2025-11-11 23:30:44,637:INFO:              mlflow: Not installed
2025-11-11 23:30:44,637:INFO:              gradio: Not installed
2025-11-11 23:30:44,638:INFO:             fastapi: Not installed
2025-11-11 23:30:44,638:INFO:             uvicorn: Not installed
2025-11-11 23:30:44,638:INFO:              m2cgen: Not installed
2025-11-11 23:30:44,638:INFO:           evidently: Not installed
2025-11-11 23:30:44,638:INFO:               fugue: Not installed
2025-11-11 23:30:44,638:INFO:           streamlit: Not installed
2025-11-11 23:30:44,638:INFO:             prophet: Not installed
2025-11-11 23:30:44,638:INFO:None
2025-11-11 23:30:44,638:INFO:Set up data.
2025-11-11 23:30:44,667:INFO:Set up folding strategy.
2025-11-11 23:30:44,667:INFO:Set up train/test split.
2025-11-11 23:30:44,692:INFO:Set up index.
2025-11-11 23:30:44,694:INFO:Assigning column types.
2025-11-11 23:30:44,708:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-11 23:30:44,782:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-11 23:30:44,792:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-11 23:30:44,852:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:30:44,854:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:30:44,920:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-11 23:30:44,921:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-11 23:30:44,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:30:44,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:30:44,968:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-11 23:30:45,042:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-11 23:30:45,098:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:30:45,100:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:30:45,173:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-11 23:30:45,218:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:30:45,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:30:45,219:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-11 23:30:45,350:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:30:45,350:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:30:45,464:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:30:45,628:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:30:45,634:INFO:Preparing preprocessing pipeline...
2025-11-11 23:30:45,636:INFO:Set up simple imputation.
2025-11-11 23:30:45,645:INFO:Set up encoding of ordinal features.
2025-11-11 23:30:45,650:INFO:Set up encoding of categorical features.
2025-11-11 23:30:45,891:INFO:Finished creating preprocessing pipeline.
2025-11-11 23:30:45,926:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\usuario\AppData\Local\Temp\2\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['education_level',
                                             'marital_status',
                                             'income_category',
                                             'card_category'],
                                    transformer=OneHotEncoder(cols=['education_level',
                                                                    'marital_status',
                                                                    'income_category',
                                                                    'card_category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-11-11 23:30:45,926:INFO:Creating final display dataframe.
2025-11-11 23:30:46,181:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target    attrition_flag
2                   Target type            Binary
3           Original data shape       (10127, 21)
4        Transformed data shape       (10127, 38)
5   Transformed train set shape        (7088, 38)
6    Transformed test set shape        (3039, 38)
7              Numeric features                15
8          Categorical features                 5
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              5622
2025-11-11 23:30:46,312:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:30:46,313:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:30:46,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:30:46,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:30:46,450:INFO:setup() successfully completed in 2.03s...............
2025-11-11 23:30:46,450:INFO:Initializing compare_models()
2025-11-11 23:30:46,450:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>, include=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>, 'include': None, 'exclude': ['ridge', 'dummy', 'svm', 'quadratic_discriminant_analysis'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['ridge', 'dummy', 'svm', 'quadratic_discriminant_analysis'])
2025-11-11 23:30:46,452:INFO:Checking exceptions
2025-11-11 23:30:46,463:INFO:Preparing display monitor
2025-11-11 23:30:46,474:INFO:Initializing Logistic Regression
2025-11-11 23:30:46,474:INFO:Total runtime is 0.0 minutes
2025-11-11 23:30:46,474:INFO:SubProcess create_model() called ==================================
2025-11-11 23:30:46,476:INFO:Initializing create_model()
2025-11-11 23:30:46,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023EAFFFF400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:30:46,477:INFO:Checking exceptions
2025-11-11 23:30:46,477:INFO:Importing libraries
2025-11-11 23:30:46,477:INFO:Copying training dataset
2025-11-11 23:30:46,501:INFO:Defining folds
2025-11-11 23:30:46,501:INFO:Declaring metric variables
2025-11-11 23:30:46,501:INFO:Importing untrained model
2025-11-11 23:30:46,502:INFO:Logistic Regression Imported successfully
2025-11-11 23:30:46,502:INFO:Starting cross validation
2025-11-11 23:30:46,506:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:30:49,717:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:30:49,755:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:30:49,826:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:30:49,868:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:30:50,123:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:30:50,156:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:30:50,160:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:30:50,186:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:30:50,190:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:30:50,202:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:30:50,698:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:30:50,805:INFO:Calculating mean and std
2025-11-11 23:30:50,810:INFO:Creating metrics dataframe
2025-11-11 23:30:50,820:INFO:Uploading results into container
2025-11-11 23:30:50,821:INFO:Uploading model into container now
2025-11-11 23:30:50,822:INFO:_master_model_container: 1
2025-11-11 23:30:50,823:INFO:_display_container: 2
2025-11-11 23:30:50,824:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-11 23:30:50,824:INFO:create_model() successfully completed......................................
2025-11-11 23:30:51,082:INFO:SubProcess create_model() end ==================================
2025-11-11 23:30:51,083:INFO:Creating metrics dataframe
2025-11-11 23:30:51,087:INFO:Initializing K Neighbors Classifier
2025-11-11 23:30:51,087:INFO:Total runtime is 0.07689271370569865 minutes
2025-11-11 23:30:51,088:INFO:SubProcess create_model() called ==================================
2025-11-11 23:30:51,088:INFO:Initializing create_model()
2025-11-11 23:30:51,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023EAFFFF400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:30:51,088:INFO:Checking exceptions
2025-11-11 23:30:51,088:INFO:Importing libraries
2025-11-11 23:30:51,088:INFO:Copying training dataset
2025-11-11 23:30:51,110:INFO:Defining folds
2025-11-11 23:30:51,110:INFO:Declaring metric variables
2025-11-11 23:30:51,110:INFO:Importing untrained model
2025-11-11 23:30:51,110:INFO:K Neighbors Classifier Imported successfully
2025-11-11 23:30:51,111:INFO:Starting cross validation
2025-11-11 23:30:51,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:30:54,220:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:30:54,291:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:30:54,378:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:30:54,391:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:30:54,406:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:30:54,420:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:30:55,388:INFO:Calculating mean and std
2025-11-11 23:30:55,391:INFO:Creating metrics dataframe
2025-11-11 23:30:55,395:INFO:Uploading results into container
2025-11-11 23:30:55,397:INFO:Uploading model into container now
2025-11-11 23:30:55,397:INFO:_master_model_container: 2
2025-11-11 23:30:55,397:INFO:_display_container: 2
2025-11-11 23:30:55,399:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-11 23:30:55,399:INFO:create_model() successfully completed......................................
2025-11-11 23:30:55,527:INFO:SubProcess create_model() end ==================================
2025-11-11 23:30:55,527:INFO:Creating metrics dataframe
2025-11-11 23:30:55,534:INFO:Initializing Naive Bayes
2025-11-11 23:30:55,534:INFO:Total runtime is 0.15099749962488812 minutes
2025-11-11 23:30:55,535:INFO:SubProcess create_model() called ==================================
2025-11-11 23:30:55,536:INFO:Initializing create_model()
2025-11-11 23:30:55,536:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023EAFFFF400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:30:55,536:INFO:Checking exceptions
2025-11-11 23:30:55,536:INFO:Importing libraries
2025-11-11 23:30:55,536:INFO:Copying training dataset
2025-11-11 23:30:55,554:INFO:Defining folds
2025-11-11 23:30:55,554:INFO:Declaring metric variables
2025-11-11 23:30:55,554:INFO:Importing untrained model
2025-11-11 23:30:55,556:INFO:Naive Bayes Imported successfully
2025-11-11 23:30:55,556:INFO:Starting cross validation
2025-11-11 23:30:55,560:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:30:55,872:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:30:55,873:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:30:55,889:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:30:55,911:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:30:55,921:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:30:55,925:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:30:55,928:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:30:55,932:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:30:55,943:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:30:55,945:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:30:55,959:INFO:Calculating mean and std
2025-11-11 23:30:55,963:INFO:Creating metrics dataframe
2025-11-11 23:30:55,968:INFO:Uploading results into container
2025-11-11 23:30:55,968:INFO:Uploading model into container now
2025-11-11 23:30:55,968:INFO:_master_model_container: 3
2025-11-11 23:30:55,970:INFO:_display_container: 2
2025-11-11 23:30:55,970:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-11 23:30:55,970:INFO:create_model() successfully completed......................................
2025-11-11 23:30:56,115:INFO:SubProcess create_model() end ==================================
2025-11-11 23:30:56,115:INFO:Creating metrics dataframe
2025-11-11 23:30:56,123:INFO:Initializing Decision Tree Classifier
2025-11-11 23:30:56,123:INFO:Total runtime is 0.16081536213556927 minutes
2025-11-11 23:30:56,124:INFO:SubProcess create_model() called ==================================
2025-11-11 23:30:56,124:INFO:Initializing create_model()
2025-11-11 23:30:56,124:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023EAFFFF400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:30:56,124:INFO:Checking exceptions
2025-11-11 23:30:56,124:INFO:Importing libraries
2025-11-11 23:30:56,124:INFO:Copying training dataset
2025-11-11 23:30:56,144:INFO:Defining folds
2025-11-11 23:30:56,144:INFO:Declaring metric variables
2025-11-11 23:30:56,145:INFO:Importing untrained model
2025-11-11 23:30:56,145:INFO:Decision Tree Classifier Imported successfully
2025-11-11 23:30:56,146:INFO:Starting cross validation
2025-11-11 23:30:56,150:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:30:56,660:INFO:Calculating mean and std
2025-11-11 23:30:56,662:INFO:Creating metrics dataframe
2025-11-11 23:30:56,667:INFO:Uploading results into container
2025-11-11 23:30:56,667:INFO:Uploading model into container now
2025-11-11 23:30:56,668:INFO:_master_model_container: 4
2025-11-11 23:30:56,668:INFO:_display_container: 2
2025-11-11 23:30:56,669:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-11-11 23:30:56,669:INFO:create_model() successfully completed......................................
2025-11-11 23:30:56,826:INFO:SubProcess create_model() end ==================================
2025-11-11 23:30:56,827:INFO:Creating metrics dataframe
2025-11-11 23:30:56,835:INFO:Initializing Random Forest Classifier
2025-11-11 23:30:56,835:INFO:Total runtime is 0.1726897120475769 minutes
2025-11-11 23:30:56,835:INFO:SubProcess create_model() called ==================================
2025-11-11 23:30:56,837:INFO:Initializing create_model()
2025-11-11 23:30:56,837:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023EAFFFF400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:30:56,838:INFO:Checking exceptions
2025-11-11 23:30:56,838:INFO:Importing libraries
2025-11-11 23:30:56,838:INFO:Copying training dataset
2025-11-11 23:30:56,856:INFO:Defining folds
2025-11-11 23:30:56,856:INFO:Declaring metric variables
2025-11-11 23:30:56,859:INFO:Importing untrained model
2025-11-11 23:30:56,859:INFO:Random Forest Classifier Imported successfully
2025-11-11 23:30:56,860:INFO:Starting cross validation
2025-11-11 23:30:56,864:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:30:58,979:INFO:Calculating mean and std
2025-11-11 23:30:58,983:INFO:Creating metrics dataframe
2025-11-11 23:30:58,988:INFO:Uploading results into container
2025-11-11 23:30:58,988:INFO:Uploading model into container now
2025-11-11 23:30:58,990:INFO:_master_model_container: 5
2025-11-11 23:30:58,990:INFO:_display_container: 2
2025-11-11 23:30:58,990:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-11-11 23:30:58,990:INFO:create_model() successfully completed......................................
2025-11-11 23:30:59,165:INFO:SubProcess create_model() end ==================================
2025-11-11 23:30:59,167:INFO:Creating metrics dataframe
2025-11-11 23:30:59,173:INFO:Initializing Quadratic Discriminant Analysis
2025-11-11 23:30:59,173:INFO:Total runtime is 0.21165881156921387 minutes
2025-11-11 23:30:59,173:INFO:SubProcess create_model() called ==================================
2025-11-11 23:30:59,173:INFO:Initializing create_model()
2025-11-11 23:30:59,173:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023EAFFFF400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:30:59,173:INFO:Checking exceptions
2025-11-11 23:30:59,173:INFO:Importing libraries
2025-11-11 23:30:59,173:INFO:Copying training dataset
2025-11-11 23:30:59,194:INFO:Defining folds
2025-11-11 23:30:59,195:INFO:Declaring metric variables
2025-11-11 23:30:59,195:INFO:Importing untrained model
2025-11-11 23:30:59,196:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-11 23:30:59,196:INFO:Starting cross validation
2025-11-11 23:30:59,201:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:30:59,452:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:30:59,457:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:30:59,463:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:30:59,486:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:30:59,487:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:30:59,495:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:30:59,495:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:30:59,506:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:30:59,514:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:30:59,552:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:30:59,651:INFO:Calculating mean and std
2025-11-11 23:30:59,654:INFO:Creating metrics dataframe
2025-11-11 23:30:59,658:INFO:Uploading results into container
2025-11-11 23:30:59,659:INFO:Uploading model into container now
2025-11-11 23:30:59,660:INFO:_master_model_container: 6
2025-11-11 23:30:59,661:INFO:_display_container: 2
2025-11-11 23:30:59,661:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-11 23:30:59,661:INFO:create_model() successfully completed......................................
2025-11-11 23:30:59,791:INFO:SubProcess create_model() end ==================================
2025-11-11 23:30:59,791:INFO:Creating metrics dataframe
2025-11-11 23:30:59,797:INFO:Initializing Ada Boost Classifier
2025-11-11 23:30:59,798:INFO:Total runtime is 0.22206354141235352 minutes
2025-11-11 23:30:59,798:INFO:SubProcess create_model() called ==================================
2025-11-11 23:30:59,798:INFO:Initializing create_model()
2025-11-11 23:30:59,798:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023EAFFFF400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:30:59,798:INFO:Checking exceptions
2025-11-11 23:30:59,798:INFO:Importing libraries
2025-11-11 23:30:59,798:INFO:Copying training dataset
2025-11-11 23:30:59,816:INFO:Defining folds
2025-11-11 23:30:59,818:INFO:Declaring metric variables
2025-11-11 23:30:59,818:INFO:Importing untrained model
2025-11-11 23:30:59,818:INFO:Ada Boost Classifier Imported successfully
2025-11-11 23:30:59,820:INFO:Starting cross validation
2025-11-11 23:30:59,824:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:31:00,054:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:31:00,058:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:31:00,068:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:31:00,070:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:31:00,073:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:31:00,075:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:31:00,079:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:31:00,084:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:31:00,098:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:31:00,117:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:31:01,111:INFO:Calculating mean and std
2025-11-11 23:31:01,115:INFO:Creating metrics dataframe
2025-11-11 23:31:01,120:INFO:Uploading results into container
2025-11-11 23:31:01,120:INFO:Uploading model into container now
2025-11-11 23:31:01,122:INFO:_master_model_container: 7
2025-11-11 23:31:01,122:INFO:_display_container: 2
2025-11-11 23:31:01,123:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-11-11 23:31:01,123:INFO:create_model() successfully completed......................................
2025-11-11 23:31:01,272:INFO:SubProcess create_model() end ==================================
2025-11-11 23:31:01,273:INFO:Creating metrics dataframe
2025-11-11 23:31:01,278:INFO:Initializing Gradient Boosting Classifier
2025-11-11 23:31:01,278:INFO:Total runtime is 0.24673601388931274 minutes
2025-11-11 23:31:01,278:INFO:SubProcess create_model() called ==================================
2025-11-11 23:31:01,278:INFO:Initializing create_model()
2025-11-11 23:31:01,280:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023EAFFFF400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:31:01,280:INFO:Checking exceptions
2025-11-11 23:31:01,280:INFO:Importing libraries
2025-11-11 23:31:01,280:INFO:Copying training dataset
2025-11-11 23:31:01,299:INFO:Defining folds
2025-11-11 23:31:01,300:INFO:Declaring metric variables
2025-11-11 23:31:01,300:INFO:Importing untrained model
2025-11-11 23:31:01,300:INFO:Gradient Boosting Classifier Imported successfully
2025-11-11 23:31:01,302:INFO:Starting cross validation
2025-11-11 23:31:01,305:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:31:04,975:INFO:Calculating mean and std
2025-11-11 23:31:04,979:INFO:Creating metrics dataframe
2025-11-11 23:31:04,983:INFO:Uploading results into container
2025-11-11 23:31:04,984:INFO:Uploading model into container now
2025-11-11 23:31:04,985:INFO:_master_model_container: 8
2025-11-11 23:31:04,985:INFO:_display_container: 2
2025-11-11 23:31:04,986:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-11 23:31:04,986:INFO:create_model() successfully completed......................................
2025-11-11 23:31:05,146:INFO:SubProcess create_model() end ==================================
2025-11-11 23:31:05,148:INFO:Creating metrics dataframe
2025-11-11 23:31:05,154:INFO:Initializing Linear Discriminant Analysis
2025-11-11 23:31:05,154:INFO:Total runtime is 0.31133015553156534 minutes
2025-11-11 23:31:05,154:INFO:SubProcess create_model() called ==================================
2025-11-11 23:31:05,154:INFO:Initializing create_model()
2025-11-11 23:31:05,154:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023EAFFFF400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:31:05,156:INFO:Checking exceptions
2025-11-11 23:31:05,156:INFO:Importing libraries
2025-11-11 23:31:05,156:INFO:Copying training dataset
2025-11-11 23:31:05,176:INFO:Defining folds
2025-11-11 23:31:05,178:INFO:Declaring metric variables
2025-11-11 23:31:05,178:INFO:Importing untrained model
2025-11-11 23:31:05,178:INFO:Linear Discriminant Analysis Imported successfully
2025-11-11 23:31:05,178:INFO:Starting cross validation
2025-11-11 23:31:05,183:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:31:05,619:INFO:Calculating mean and std
2025-11-11 23:31:05,623:INFO:Creating metrics dataframe
2025-11-11 23:31:05,629:INFO:Uploading results into container
2025-11-11 23:31:05,629:INFO:Uploading model into container now
2025-11-11 23:31:05,631:INFO:_master_model_container: 9
2025-11-11 23:31:05,631:INFO:_display_container: 2
2025-11-11 23:31:05,631:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-11 23:31:05,631:INFO:create_model() successfully completed......................................
2025-11-11 23:31:05,769:INFO:SubProcess create_model() end ==================================
2025-11-11 23:31:05,769:INFO:Creating metrics dataframe
2025-11-11 23:31:05,775:INFO:Initializing Extra Trees Classifier
2025-11-11 23:31:05,775:INFO:Total runtime is 0.3216902732849121 minutes
2025-11-11 23:31:05,775:INFO:SubProcess create_model() called ==================================
2025-11-11 23:31:05,775:INFO:Initializing create_model()
2025-11-11 23:31:05,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023EAFFFF400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:31:05,775:INFO:Checking exceptions
2025-11-11 23:31:05,775:INFO:Importing libraries
2025-11-11 23:31:05,777:INFO:Copying training dataset
2025-11-11 23:31:05,798:INFO:Defining folds
2025-11-11 23:31:05,799:INFO:Declaring metric variables
2025-11-11 23:31:05,799:INFO:Importing untrained model
2025-11-11 23:31:05,800:INFO:Extra Trees Classifier Imported successfully
2025-11-11 23:31:05,801:INFO:Starting cross validation
2025-11-11 23:31:05,805:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:31:07,390:INFO:Calculating mean and std
2025-11-11 23:31:07,394:INFO:Creating metrics dataframe
2025-11-11 23:31:07,399:INFO:Uploading results into container
2025-11-11 23:31:07,400:INFO:Uploading model into container now
2025-11-11 23:31:07,401:INFO:_master_model_container: 10
2025-11-11 23:31:07,401:INFO:_display_container: 2
2025-11-11 23:31:07,402:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-11-11 23:31:07,402:INFO:create_model() successfully completed......................................
2025-11-11 23:31:07,537:INFO:SubProcess create_model() end ==================================
2025-11-11 23:31:07,537:INFO:Creating metrics dataframe
2025-11-11 23:31:07,543:INFO:Initializing Light Gradient Boosting Machine
2025-11-11 23:31:07,543:INFO:Total runtime is 0.3511569619178772 minutes
2025-11-11 23:31:07,543:INFO:SubProcess create_model() called ==================================
2025-11-11 23:31:07,543:INFO:Initializing create_model()
2025-11-11 23:31:07,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023EAFFFF400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:31:07,543:INFO:Checking exceptions
2025-11-11 23:31:07,543:INFO:Importing libraries
2025-11-11 23:31:07,543:INFO:Copying training dataset
2025-11-11 23:31:07,562:INFO:Defining folds
2025-11-11 23:31:07,562:INFO:Declaring metric variables
2025-11-11 23:31:07,562:INFO:Importing untrained model
2025-11-11 23:31:07,562:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-11 23:31:07,564:INFO:Starting cross validation
2025-11-11 23:31:07,569:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:31:28,741:INFO:Calculating mean and std
2025-11-11 23:31:28,745:INFO:Creating metrics dataframe
2025-11-11 23:31:28,749:INFO:Uploading results into container
2025-11-11 23:31:28,751:INFO:Uploading model into container now
2025-11-11 23:31:28,751:INFO:_master_model_container: 11
2025-11-11 23:31:28,751:INFO:_display_container: 2
2025-11-11 23:31:28,753:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-11 23:31:28,753:INFO:create_model() successfully completed......................................
2025-11-11 23:31:28,901:INFO:SubProcess create_model() end ==================================
2025-11-11 23:31:28,901:INFO:Creating metrics dataframe
2025-11-11 23:31:28,912:INFO:Initializing create_model()
2025-11-11 23:31:28,912:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:31:28,912:INFO:Checking exceptions
2025-11-11 23:31:28,914:INFO:Importing libraries
2025-11-11 23:31:28,914:INFO:Copying training dataset
2025-11-11 23:31:28,932:INFO:Defining folds
2025-11-11 23:31:28,932:INFO:Declaring metric variables
2025-11-11 23:31:28,932:INFO:Importing untrained model
2025-11-11 23:31:28,932:INFO:Declaring custom model
2025-11-11 23:31:28,934:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-11 23:31:28,936:INFO:Cross validation set to False
2025-11-11 23:31:28,936:INFO:Fitting Model
2025-11-11 23:31:29,169:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-11 23:31:29,170:INFO:[LightGBM] [Info] Number of positive: 1139, number of negative: 5949
2025-11-11 23:31:29,176:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002970 seconds.
2025-11-11 23:31:29,176:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-11 23:31:29,177:INFO:[LightGBM] [Info] Total Bins 2320
2025-11-11 23:31:29,177:INFO:[LightGBM] [Info] Number of data points in the train set: 7088, number of used features: 36
2025-11-11 23:31:29,178:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160694 -> initscore=-1.653072
2025-11-11 23:31:29,178:INFO:[LightGBM] [Info] Start training from score -1.653072
2025-11-11 23:31:30,695:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-11 23:31:30,695:INFO:create_model() successfully completed......................................
2025-11-11 23:31:30,861:INFO:_master_model_container: 11
2025-11-11 23:31:30,863:INFO:_display_container: 2
2025-11-11 23:31:30,863:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-11 23:31:30,863:INFO:compare_models() successfully completed......................................
2025-11-11 23:31:30,886:INFO:Initializing tune_model()
2025-11-11 23:31:30,888:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=30, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>)
2025-11-11 23:31:30,888:INFO:Checking exceptions
2025-11-11 23:31:30,902:INFO:Copying training dataset
2025-11-11 23:31:30,915:INFO:Checking base model
2025-11-11 23:31:30,915:INFO:Base model : Light Gradient Boosting Machine
2025-11-11 23:31:30,916:INFO:Declaring metric variables
2025-11-11 23:31:30,916:INFO:Defining Hyperparameters
2025-11-11 23:31:31,076:INFO:Tuning with n_jobs=-1
2025-11-11 23:31:31,076:INFO:Initializing RandomizedSearchCV
2025-11-11 23:38:30,656:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.2, 'actual_estimator__num_leaves': 40, 'actual_estimator__n_estimators': 160, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.4}
2025-11-11 23:38:30,663:INFO:Hyperparameter search completed
2025-11-11 23:38:30,663:INFO:SubProcess create_model() called ==================================
2025-11-11 23:38:30,665:INFO:Initializing create_model()
2025-11-11 23:38:30,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023EAAF3FA60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.2, 'num_leaves': 40, 'n_estimators': 160, 'min_split_gain': 0.4, 'min_child_samples': 6, 'learning_rate': 0.1, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.4})
2025-11-11 23:38:30,665:INFO:Checking exceptions
2025-11-11 23:38:30,665:INFO:Importing libraries
2025-11-11 23:38:30,667:INFO:Copying training dataset
2025-11-11 23:38:30,692:INFO:Defining folds
2025-11-11 23:38:30,692:INFO:Declaring metric variables
2025-11-11 23:38:30,693:INFO:Importing untrained model
2025-11-11 23:38:30,693:INFO:Declaring custom model
2025-11-11 23:38:30,696:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-11 23:38:30,697:INFO:Starting cross validation
2025-11-11 23:38:30,701:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:39:01,636:INFO:Calculating mean and std
2025-11-11 23:39:01,641:INFO:Creating metrics dataframe
2025-11-11 23:39:01,645:INFO:Finalizing model
2025-11-11 23:39:01,868:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-11 23:39:01,868:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-11 23:39:01,868:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-11 23:39:01,882:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-11 23:39:01,882:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-11 23:39:01,882:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-11 23:39:01,883:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-11 23:39:01,884:INFO:[LightGBM] [Info] Number of positive: 1139, number of negative: 5949
2025-11-11 23:39:01,888:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002235 seconds.
2025-11-11 23:39:01,888:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-11 23:39:01,889:INFO:[LightGBM] [Info] Total Bins 2322
2025-11-11 23:39:01,889:INFO:[LightGBM] [Info] Number of data points in the train set: 7088, number of used features: 37
2025-11-11 23:39:01,890:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160694 -> initscore=-1.653072
2025-11-11 23:39:01,890:INFO:[LightGBM] [Info] Start training from score -1.653072
2025-11-11 23:39:02,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:02,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:03,140:INFO:Uploading results into container
2025-11-11 23:39:03,143:INFO:Uploading model into container now
2025-11-11 23:39:03,144:INFO:_master_model_container: 12
2025-11-11 23:39:03,144:INFO:_display_container: 3
2025-11-11 23:39:03,146:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-11 23:39:03,146:INFO:create_model() successfully completed......................................
2025-11-11 23:39:03,395:INFO:SubProcess create_model() end ==================================
2025-11-11 23:39:03,395:INFO:choose_better activated
2025-11-11 23:39:03,397:INFO:SubProcess create_model() called ==================================
2025-11-11 23:39:03,399:INFO:Initializing create_model()
2025-11-11 23:39:03,399:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:39:03,399:INFO:Checking exceptions
2025-11-11 23:39:03,401:INFO:Importing libraries
2025-11-11 23:39:03,401:INFO:Copying training dataset
2025-11-11 23:39:03,418:INFO:Defining folds
2025-11-11 23:39:03,418:INFO:Declaring metric variables
2025-11-11 23:39:03,418:INFO:Importing untrained model
2025-11-11 23:39:03,418:INFO:Declaring custom model
2025-11-11 23:39:03,422:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-11 23:39:03,423:INFO:Starting cross validation
2025-11-11 23:39:03,425:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:39:24,676:INFO:Calculating mean and std
2025-11-11 23:39:24,676:INFO:Creating metrics dataframe
2025-11-11 23:39:24,680:INFO:Finalizing model
2025-11-11 23:39:24,873:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-11 23:39:24,874:INFO:[LightGBM] [Info] Number of positive: 1139, number of negative: 5949
2025-11-11 23:39:24,878:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002974 seconds.
2025-11-11 23:39:24,878:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-11 23:39:24,879:INFO:[LightGBM] [Info] Total Bins 2320
2025-11-11 23:39:24,880:INFO:[LightGBM] [Info] Number of data points in the train set: 7088, number of used features: 36
2025-11-11 23:39:24,881:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160694 -> initscore=-1.653072
2025-11-11 23:39:24,881:INFO:[LightGBM] [Info] Start training from score -1.653072
2025-11-11 23:39:26,607:INFO:Uploading results into container
2025-11-11 23:39:26,609:INFO:Uploading model into container now
2025-11-11 23:39:26,609:INFO:_master_model_container: 13
2025-11-11 23:39:26,609:INFO:_display_container: 4
2025-11-11 23:39:26,611:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-11 23:39:26,611:INFO:create_model() successfully completed......................................
2025-11-11 23:39:26,750:INFO:SubProcess create_model() end ==================================
2025-11-11 23:39:26,751:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8911
2025-11-11 23:39:26,753:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.892
2025-11-11 23:39:26,754:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-11-11 23:39:26,754:INFO:choose_better completed
2025-11-11 23:39:26,763:INFO:_master_model_container: 13
2025-11-11 23:39:26,764:INFO:_display_container: 3
2025-11-11 23:39:26,765:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-11 23:39:26,765:INFO:tune_model() successfully completed......................................
2025-11-11 23:39:26,926:INFO:Initializing finalize_model()
2025-11-11 23:39:26,926:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>, estimator=LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-11-11 23:39:26,928:INFO:Finalizing LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-11 23:39:26,940:INFO:Initializing create_model()
2025-11-11 23:39:26,940:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023EAAFB9760>, estimator=LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:39:26,940:INFO:Checking exceptions
2025-11-11 23:39:26,942:INFO:Importing libraries
2025-11-11 23:39:26,942:INFO:Copying training dataset
2025-11-11 23:39:26,942:INFO:Defining folds
2025-11-11 23:39:26,942:INFO:Declaring metric variables
2025-11-11 23:39:26,942:INFO:Importing untrained model
2025-11-11 23:39:26,942:INFO:Declaring custom model
2025-11-11 23:39:26,944:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-11 23:39:26,950:INFO:Cross validation set to False
2025-11-11 23:39:26,950:INFO:Fitting Model
2025-11-11 23:39:27,181:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-11 23:39:27,181:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-11 23:39:27,181:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-11 23:39:27,199:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-11 23:39:27,200:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-11 23:39:27,200:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-11 23:39:27,200:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-11 23:39:27,200:INFO:[LightGBM] [Info] Number of positive: 1627, number of negative: 8500
2025-11-11 23:39:27,205:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002213 seconds.
2025-11-11 23:39:27,205:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-11 23:39:27,205:INFO:[LightGBM] [Info] Total Bins 2324
2025-11-11 23:39:27,208:INFO:[LightGBM] [Info] Number of data points in the train set: 10127, number of used features: 37
2025-11-11 23:39:27,209:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160660 -> initscore=-1.653328
2025-11-11 23:39:27,209:INFO:[LightGBM] [Info] Start training from score -1.653328
2025-11-11 23:39:28,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:28,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:29,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:29,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:29,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:29,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:29,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:29,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:29,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:29,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:29,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:29,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:29,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:29,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-11 23:39:29,141:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-11 23:39:29,142:INFO:create_model() successfully completed......................................
2025-11-11 23:39:29,285:INFO:_master_model_container: 13
2025-11-11 23:39:29,285:INFO:_display_container: 3
2025-11-11 23:39:29,324:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-11 23:39:29,324:INFO:finalize_model() successfully completed......................................
2025-11-11 23:39:29,517:INFO:Initializing save_model()
2025-11-11 23:39:29,517:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=pycaret_best_automl_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\usuario\AppData\Local\Temp\2\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['education_level',
                                             'marital_status',
                                             'income_category',
                                             'card_category'],
                                    transformer=OneHotEncoder(cols=['education_level',
                                                                    'marital_status',
                                                                    'income_category',
                                                                    'card_category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-11-11 23:39:29,517:INFO:Adding model into prep_pipe
2025-11-11 23:39:29,517:WARNING:Only Model saved as it was a pipeline.
2025-11-11 23:39:29,554:INFO:pycaret_best_automl_model.pkl saved in current working directory
2025-11-11 23:39:29,591:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-11 23:39:29,591:INFO:save_model() successfully completed......................................
2025-11-11 23:39:29,724:INFO:Initializing load_model()
2025-11-11 23:39:29,724:INFO:load_model(model_name=pycaret_best_automl_model, platform=None, authentication=None, verbose=False)
2025-11-11 23:48:11,660:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 23:48:11,661:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 23:48:11,661:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 23:48:11,661:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-11-11 23:51:54,274:INFO:PyCaret ClassificationExperiment
2025-11-11 23:51:54,274:INFO:Logging name: clf-default-name
2025-11-11 23:51:54,274:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-11 23:51:54,274:INFO:version 3.3.2
2025-11-11 23:51:54,274:INFO:Initializing setup()
2025-11-11 23:51:54,274:INFO:self.USI: 7ecd
2025-11-11 23:51:54,274:INFO:self._variable_keys: {'fold_generator', 'log_plots_param', 'html_param', 'X', 'fold_shuffle_param', 'gpu_param', 'X_test', 'memory', 'is_multiclass', 'seed', 'target_param', 'X_train', 'y_train', 'exp_id', 'fold_groups_param', 'idx', 'n_jobs_param', 'exp_name_log', 'data', '_ml_usecase', 'y_test', '_available_plots', 'y', 'gpu_n_jobs_param', 'fix_imbalance', 'USI', 'logging_param', 'pipeline'}
2025-11-11 23:51:54,274:INFO:Checking environment
2025-11-11 23:51:54,274:INFO:python_version: 3.9.10
2025-11-11 23:51:54,274:INFO:python_build: ('tags/v3.9.10:f2f3f53', 'Jan 17 2022 15:14:21')
2025-11-11 23:51:54,274:INFO:machine: AMD64
2025-11-11 23:51:54,276:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-11 23:51:54,279:INFO:Memory: svmem(total=42001428480, available=28279283712, percent=32.7, used=13722144768, free=28279283712)
2025-11-11 23:51:54,279:INFO:Physical Core: 16
2025-11-11 23:51:54,279:INFO:Logical Core: 16
2025-11-11 23:51:54,279:INFO:Checking libraries
2025-11-11 23:51:54,279:INFO:System:
2025-11-11 23:51:54,279:INFO:    python: 3.9.10 (tags/v3.9.10:f2f3f53, Jan 17 2022, 15:14:21) [MSC v.1929 64 bit (AMD64)]
2025-11-11 23:51:54,281:INFO:executable: C:\Users\usuario\PycharmProjects\PythonProject\.venv\Scripts\python.exe
2025-11-11 23:51:54,281:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-11 23:51:54,281:INFO:PyCaret required dependencies:
2025-11-11 23:51:54,384:INFO:                 pip: 25.3
2025-11-11 23:51:54,384:INFO:          setuptools: 80.3.1
2025-11-11 23:51:54,384:INFO:             pycaret: 3.3.2
2025-11-11 23:51:54,384:INFO:             IPython: 8.18.1
2025-11-11 23:51:54,384:INFO:          ipywidgets: 8.1.8
2025-11-11 23:51:54,384:INFO:                tqdm: 4.67.1
2025-11-11 23:51:54,384:INFO:               numpy: 1.26.4
2025-11-11 23:51:54,385:INFO:              pandas: 2.1.4
2025-11-11 23:51:54,385:INFO:              jinja2: 3.1.6
2025-11-11 23:51:54,385:INFO:               scipy: 1.11.4
2025-11-11 23:51:54,385:INFO:              joblib: 1.3.2
2025-11-11 23:51:54,386:INFO:             sklearn: 1.4.2
2025-11-11 23:51:54,386:INFO:                pyod: 2.0.5
2025-11-11 23:51:54,386:INFO:            imblearn: 0.12.4
2025-11-11 23:51:54,386:INFO:   category_encoders: 2.6.4
2025-11-11 23:51:54,386:INFO:            lightgbm: 4.6.0
2025-11-11 23:51:54,386:INFO:               numba: 0.60.0
2025-11-11 23:51:54,386:INFO:            requests: 2.32.5
2025-11-11 23:51:54,386:INFO:          matplotlib: 3.7.5
2025-11-11 23:51:54,386:INFO:          scikitplot: 0.3.7
2025-11-11 23:51:54,387:INFO:         yellowbrick: 1.5
2025-11-11 23:51:54,387:INFO:              plotly: 6.4.0
2025-11-11 23:51:54,387:INFO:    plotly-resampler: Not installed
2025-11-11 23:51:54,387:INFO:             kaleido: 1.2.0
2025-11-11 23:51:54,387:INFO:           schemdraw: 0.15
2025-11-11 23:51:54,387:INFO:         statsmodels: 0.14.5
2025-11-11 23:51:54,387:INFO:              sktime: 0.26.0
2025-11-11 23:51:54,387:INFO:               tbats: 1.1.3
2025-11-11 23:51:54,387:INFO:            pmdarima: 2.0.4
2025-11-11 23:51:54,387:INFO:              psutil: 7.1.3
2025-11-11 23:51:54,387:INFO:          markupsafe: 3.0.3
2025-11-11 23:51:54,387:INFO:             pickle5: Not installed
2025-11-11 23:51:54,388:INFO:         cloudpickle: 3.1.2
2025-11-11 23:51:54,388:INFO:         deprecation: 2.1.0
2025-11-11 23:51:54,388:INFO:              xxhash: 3.6.0
2025-11-11 23:51:54,388:INFO:           wurlitzer: Not installed
2025-11-11 23:51:54,388:INFO:PyCaret optional dependencies:
2025-11-11 23:51:54,477:INFO:                shap: Not installed
2025-11-11 23:51:54,477:INFO:           interpret: Not installed
2025-11-11 23:51:54,477:INFO:                umap: Not installed
2025-11-11 23:51:54,478:INFO:     ydata_profiling: Not installed
2025-11-11 23:51:54,478:INFO:  explainerdashboard: Not installed
2025-11-11 23:51:54,478:INFO:             autoviz: Not installed
2025-11-11 23:51:54,478:INFO:           fairlearn: Not installed
2025-11-11 23:51:54,478:INFO:          deepchecks: Not installed
2025-11-11 23:51:54,478:INFO:             xgboost: Not installed
2025-11-11 23:51:54,478:INFO:            catboost: Not installed
2025-11-11 23:51:54,478:INFO:              kmodes: Not installed
2025-11-11 23:51:54,478:INFO:             mlxtend: Not installed
2025-11-11 23:51:54,478:INFO:       statsforecast: Not installed
2025-11-11 23:51:54,478:INFO:        tune_sklearn: Not installed
2025-11-11 23:51:54,478:INFO:                 ray: Not installed
2025-11-11 23:51:54,478:INFO:            hyperopt: Not installed
2025-11-11 23:51:54,479:INFO:              optuna: Not installed
2025-11-11 23:51:54,479:INFO:               skopt: Not installed
2025-11-11 23:51:54,479:INFO:              mlflow: Not installed
2025-11-11 23:51:54,479:INFO:              gradio: Not installed
2025-11-11 23:51:54,479:INFO:             fastapi: Not installed
2025-11-11 23:51:54,479:INFO:             uvicorn: Not installed
2025-11-11 23:51:54,479:INFO:              m2cgen: Not installed
2025-11-11 23:51:54,480:INFO:           evidently: Not installed
2025-11-11 23:51:54,480:INFO:               fugue: Not installed
2025-11-11 23:51:54,480:INFO:           streamlit: Not installed
2025-11-11 23:51:54,480:INFO:             prophet: Not installed
2025-11-11 23:51:54,480:INFO:None
2025-11-11 23:51:54,480:INFO:Set up data.
2025-11-11 23:51:54,507:INFO:Set up folding strategy.
2025-11-11 23:51:54,507:INFO:Set up train/test split.
2025-11-11 23:51:54,535:INFO:Set up index.
2025-11-11 23:51:54,536:INFO:Assigning column types.
2025-11-11 23:51:54,551:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-11 23:51:54,635:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-11 23:51:54,645:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-11 23:51:54,706:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:51:54,706:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:51:54,773:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-11 23:51:54,773:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-11 23:51:54,816:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:51:54,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:51:54,816:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-11 23:51:54,884:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-11 23:51:54,924:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:51:54,925:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:51:54,991:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-11 23:51:55,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:51:55,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:51:55,035:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-11 23:51:55,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:51:55,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:51:55,260:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:51:55,262:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:51:55,268:INFO:Preparing preprocessing pipeline...
2025-11-11 23:51:55,269:INFO:Set up simple imputation.
2025-11-11 23:51:55,280:INFO:Set up encoding of ordinal features.
2025-11-11 23:51:55,286:INFO:Set up encoding of categorical features.
2025-11-11 23:51:55,521:INFO:Finished creating preprocessing pipeline.
2025-11-11 23:51:55,557:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\usuario\AppData\Local\Temp\2\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['education_level',
                                             'marital_status',
                                             'income_category',
                                             'card_category'],
                                    transformer=OneHotEncoder(cols=['education_level',
                                                                    'marital_status',
                                                                    'income_category',
                                                                    'card_category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-11-11 23:51:55,557:INFO:Creating final display dataframe.
2025-11-11 23:51:55,763:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target    attrition_flag
2                   Target type            Binary
3           Original data shape       (10127, 21)
4        Transformed data shape       (10127, 38)
5   Transformed train set shape        (7088, 38)
6    Transformed test set shape        (3039, 38)
7              Numeric features                15
8          Categorical features                 5
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              7ecd
2025-11-11 23:51:55,869:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:51:55,869:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:51:55,971:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:51:55,971:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-11 23:51:55,973:INFO:setup() successfully completed in 1.72s...............
2025-11-11 23:51:55,973:INFO:Initializing compare_models()
2025-11-11 23:51:55,973:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>, include=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>, 'include': None, 'exclude': ['ridge', 'dummy', 'svm', 'quadratic_discriminant_analysis'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['ridge', 'dummy', 'svm', 'quadratic_discriminant_analysis'])
2025-11-11 23:51:55,973:INFO:Checking exceptions
2025-11-11 23:51:55,988:INFO:Preparing display monitor
2025-11-11 23:51:55,996:INFO:Initializing Logistic Regression
2025-11-11 23:51:55,996:INFO:Total runtime is 0.0 minutes
2025-11-11 23:51:55,996:INFO:SubProcess create_model() called ==================================
2025-11-11 23:51:55,998:INFO:Initializing create_model()
2025-11-11 23:51:55,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6FE4ABE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:51:55,998:INFO:Checking exceptions
2025-11-11 23:51:55,998:INFO:Importing libraries
2025-11-11 23:51:55,998:INFO:Copying training dataset
2025-11-11 23:51:56,016:INFO:Defining folds
2025-11-11 23:51:56,016:INFO:Declaring metric variables
2025-11-11 23:51:56,016:INFO:Importing untrained model
2025-11-11 23:51:56,019:INFO:Logistic Regression Imported successfully
2025-11-11 23:51:56,019:INFO:Starting cross validation
2025-11-11 23:51:56,021:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:51:59,340:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:51:59,455:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:51:59,467:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:51:59,506:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:51:59,635:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:51:59,659:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:51:59,696:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:51:59,733:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:51:59,737:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:51:59,741:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:52:00,219:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:52:00,348:INFO:Calculating mean and std
2025-11-11 23:52:00,352:INFO:Creating metrics dataframe
2025-11-11 23:52:00,355:INFO:Uploading results into container
2025-11-11 23:52:00,357:INFO:Uploading model into container now
2025-11-11 23:52:00,357:INFO:_master_model_container: 1
2025-11-11 23:52:00,357:INFO:_display_container: 2
2025-11-11 23:52:00,359:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-11 23:52:00,360:INFO:create_model() successfully completed......................................
2025-11-11 23:52:00,616:INFO:SubProcess create_model() end ==================================
2025-11-11 23:52:00,616:INFO:Creating metrics dataframe
2025-11-11 23:52:00,622:INFO:Initializing K Neighbors Classifier
2025-11-11 23:52:00,622:INFO:Total runtime is 0.07710509697596232 minutes
2025-11-11 23:52:00,622:INFO:SubProcess create_model() called ==================================
2025-11-11 23:52:00,622:INFO:Initializing create_model()
2025-11-11 23:52:00,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6FE4ABE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:52:00,622:INFO:Checking exceptions
2025-11-11 23:52:00,622:INFO:Importing libraries
2025-11-11 23:52:00,625:INFO:Copying training dataset
2025-11-11 23:52:00,646:INFO:Defining folds
2025-11-11 23:52:00,646:INFO:Declaring metric variables
2025-11-11 23:52:00,646:INFO:Importing untrained model
2025-11-11 23:52:00,647:INFO:K Neighbors Classifier Imported successfully
2025-11-11 23:52:00,647:INFO:Starting cross validation
2025-11-11 23:52:00,651:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:52:03,708:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:52:03,788:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:52:03,807:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:52:03,851:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:52:03,881:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:52:03,885:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-11 23:52:04,846:INFO:Calculating mean and std
2025-11-11 23:52:04,850:INFO:Creating metrics dataframe
2025-11-11 23:52:04,853:INFO:Uploading results into container
2025-11-11 23:52:04,855:INFO:Uploading model into container now
2025-11-11 23:52:04,855:INFO:_master_model_container: 2
2025-11-11 23:52:04,855:INFO:_display_container: 2
2025-11-11 23:52:04,855:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-11 23:52:04,855:INFO:create_model() successfully completed......................................
2025-11-11 23:52:05,002:INFO:SubProcess create_model() end ==================================
2025-11-11 23:52:05,005:INFO:Creating metrics dataframe
2025-11-11 23:52:05,009:INFO:Initializing Naive Bayes
2025-11-11 23:52:05,009:INFO:Total runtime is 0.15022122065226237 minutes
2025-11-11 23:52:05,012:INFO:SubProcess create_model() called ==================================
2025-11-11 23:52:05,012:INFO:Initializing create_model()
2025-11-11 23:52:05,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6FE4ABE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:52:05,012:INFO:Checking exceptions
2025-11-11 23:52:05,012:INFO:Importing libraries
2025-11-11 23:52:05,012:INFO:Copying training dataset
2025-11-11 23:52:05,032:INFO:Defining folds
2025-11-11 23:52:05,032:INFO:Declaring metric variables
2025-11-11 23:52:05,032:INFO:Importing untrained model
2025-11-11 23:52:05,033:INFO:Naive Bayes Imported successfully
2025-11-11 23:52:05,034:INFO:Starting cross validation
2025-11-11 23:52:05,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:52:05,363:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:52:05,374:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:52:05,381:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:52:05,384:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:52:05,389:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:52:05,399:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:52:05,410:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:52:05,413:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:52:05,417:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:52:05,420:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-11 23:52:05,437:INFO:Calculating mean and std
2025-11-11 23:52:05,441:INFO:Creating metrics dataframe
2025-11-11 23:52:05,445:INFO:Uploading results into container
2025-11-11 23:52:05,446:INFO:Uploading model into container now
2025-11-11 23:52:05,447:INFO:_master_model_container: 3
2025-11-11 23:52:05,447:INFO:_display_container: 2
2025-11-11 23:52:05,447:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-11 23:52:05,447:INFO:create_model() successfully completed......................................
2025-11-11 23:52:05,619:INFO:SubProcess create_model() end ==================================
2025-11-11 23:52:05,621:INFO:Creating metrics dataframe
2025-11-11 23:52:05,625:INFO:Initializing Decision Tree Classifier
2025-11-11 23:52:05,625:INFO:Total runtime is 0.16048786640167237 minutes
2025-11-11 23:52:05,625:INFO:SubProcess create_model() called ==================================
2025-11-11 23:52:05,627:INFO:Initializing create_model()
2025-11-11 23:52:05,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6FE4ABE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:52:05,627:INFO:Checking exceptions
2025-11-11 23:52:05,627:INFO:Importing libraries
2025-11-11 23:52:05,628:INFO:Copying training dataset
2025-11-11 23:52:05,644:INFO:Defining folds
2025-11-11 23:52:05,645:INFO:Declaring metric variables
2025-11-11 23:52:05,645:INFO:Importing untrained model
2025-11-11 23:52:05,645:INFO:Decision Tree Classifier Imported successfully
2025-11-11 23:52:05,648:INFO:Starting cross validation
2025-11-11 23:52:05,650:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:52:06,149:INFO:Calculating mean and std
2025-11-11 23:52:06,152:INFO:Creating metrics dataframe
2025-11-11 23:52:06,157:INFO:Uploading results into container
2025-11-11 23:52:06,159:INFO:Uploading model into container now
2025-11-11 23:52:06,159:INFO:_master_model_container: 4
2025-11-11 23:52:06,159:INFO:_display_container: 2
2025-11-11 23:52:06,159:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-11-11 23:52:06,161:INFO:create_model() successfully completed......................................
2025-11-11 23:52:06,317:INFO:SubProcess create_model() end ==================================
2025-11-11 23:52:06,317:INFO:Creating metrics dataframe
2025-11-11 23:52:06,323:INFO:Initializing Random Forest Classifier
2025-11-11 23:52:06,323:INFO:Total runtime is 0.17211997906366985 minutes
2025-11-11 23:52:06,323:INFO:SubProcess create_model() called ==================================
2025-11-11 23:52:06,323:INFO:Initializing create_model()
2025-11-11 23:52:06,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6FE4ABE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:52:06,323:INFO:Checking exceptions
2025-11-11 23:52:06,323:INFO:Importing libraries
2025-11-11 23:52:06,323:INFO:Copying training dataset
2025-11-11 23:52:06,344:INFO:Defining folds
2025-11-11 23:52:06,344:INFO:Declaring metric variables
2025-11-11 23:52:06,344:INFO:Importing untrained model
2025-11-11 23:52:06,344:INFO:Random Forest Classifier Imported successfully
2025-11-11 23:52:06,346:INFO:Starting cross validation
2025-11-11 23:52:06,349:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:52:08,396:INFO:Calculating mean and std
2025-11-11 23:52:08,400:INFO:Creating metrics dataframe
2025-11-11 23:52:08,405:INFO:Uploading results into container
2025-11-11 23:52:08,408:INFO:Uploading model into container now
2025-11-11 23:52:08,409:INFO:_master_model_container: 5
2025-11-11 23:52:08,409:INFO:_display_container: 2
2025-11-11 23:52:08,410:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-11-11 23:52:08,410:INFO:create_model() successfully completed......................................
2025-11-11 23:52:08,563:INFO:SubProcess create_model() end ==================================
2025-11-11 23:52:08,563:INFO:Creating metrics dataframe
2025-11-11 23:52:08,569:INFO:Initializing Quadratic Discriminant Analysis
2025-11-11 23:52:08,569:INFO:Total runtime is 0.20954953432083132 minutes
2025-11-11 23:52:08,569:INFO:SubProcess create_model() called ==================================
2025-11-11 23:52:08,571:INFO:Initializing create_model()
2025-11-11 23:52:08,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6FE4ABE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:52:08,571:INFO:Checking exceptions
2025-11-11 23:52:08,572:INFO:Importing libraries
2025-11-11 23:52:08,572:INFO:Copying training dataset
2025-11-11 23:52:08,591:INFO:Defining folds
2025-11-11 23:52:08,591:INFO:Declaring metric variables
2025-11-11 23:52:08,591:INFO:Importing untrained model
2025-11-11 23:52:08,592:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-11 23:52:08,592:INFO:Starting cross validation
2025-11-11 23:52:08,597:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:52:08,851:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:52:08,873:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:52:08,876:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:52:08,878:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:52:08,888:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:52:08,892:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:52:08,898:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:52:08,903:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:52:08,907:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:52:08,908:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-11 23:52:09,011:INFO:Calculating mean and std
2025-11-11 23:52:09,015:INFO:Creating metrics dataframe
2025-11-11 23:52:09,020:INFO:Uploading results into container
2025-11-11 23:52:09,020:INFO:Uploading model into container now
2025-11-11 23:52:09,022:INFO:_master_model_container: 6
2025-11-11 23:52:09,022:INFO:_display_container: 2
2025-11-11 23:52:09,022:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-11 23:52:09,022:INFO:create_model() successfully completed......................................
2025-11-11 23:52:09,160:INFO:SubProcess create_model() end ==================================
2025-11-11 23:52:09,161:INFO:Creating metrics dataframe
2025-11-11 23:52:09,167:INFO:Initializing Ada Boost Classifier
2025-11-11 23:52:09,167:INFO:Total runtime is 0.21952042182286582 minutes
2025-11-11 23:52:09,167:INFO:SubProcess create_model() called ==================================
2025-11-11 23:52:09,169:INFO:Initializing create_model()
2025-11-11 23:52:09,169:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6FE4ABE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:52:09,169:INFO:Checking exceptions
2025-11-11 23:52:09,169:INFO:Importing libraries
2025-11-11 23:52:09,170:INFO:Copying training dataset
2025-11-11 23:52:09,189:INFO:Defining folds
2025-11-11 23:52:09,189:INFO:Declaring metric variables
2025-11-11 23:52:09,190:INFO:Importing untrained model
2025-11-11 23:52:09,190:INFO:Ada Boost Classifier Imported successfully
2025-11-11 23:52:09,191:INFO:Starting cross validation
2025-11-11 23:52:09,195:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:52:09,431:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:52:09,437:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:52:09,438:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:52:09,438:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:52:09,445:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:52:09,458:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:52:09,460:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:52:09,464:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:52:09,469:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:52:09,471:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-11 23:52:10,382:INFO:Calculating mean and std
2025-11-11 23:52:10,385:INFO:Creating metrics dataframe
2025-11-11 23:52:10,390:INFO:Uploading results into container
2025-11-11 23:52:10,391:INFO:Uploading model into container now
2025-11-11 23:52:10,392:INFO:_master_model_container: 7
2025-11-11 23:52:10,392:INFO:_display_container: 2
2025-11-11 23:52:10,393:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-11-11 23:52:10,393:INFO:create_model() successfully completed......................................
2025-11-11 23:52:10,568:INFO:SubProcess create_model() end ==================================
2025-11-11 23:52:10,568:INFO:Creating metrics dataframe
2025-11-11 23:52:10,573:INFO:Initializing Gradient Boosting Classifier
2025-11-11 23:52:10,573:INFO:Total runtime is 0.24295155207316083 minutes
2025-11-11 23:52:10,573:INFO:SubProcess create_model() called ==================================
2025-11-11 23:52:10,573:INFO:Initializing create_model()
2025-11-11 23:52:10,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6FE4ABE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:52:10,573:INFO:Checking exceptions
2025-11-11 23:52:10,573:INFO:Importing libraries
2025-11-11 23:52:10,573:INFO:Copying training dataset
2025-11-11 23:52:10,591:INFO:Defining folds
2025-11-11 23:52:10,592:INFO:Declaring metric variables
2025-11-11 23:52:10,593:INFO:Importing untrained model
2025-11-11 23:52:10,593:INFO:Gradient Boosting Classifier Imported successfully
2025-11-11 23:52:10,594:INFO:Starting cross validation
2025-11-11 23:52:10,597:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:52:14,097:INFO:Calculating mean and std
2025-11-11 23:52:14,101:INFO:Creating metrics dataframe
2025-11-11 23:52:14,103:INFO:Uploading results into container
2025-11-11 23:52:14,105:INFO:Uploading model into container now
2025-11-11 23:52:14,105:INFO:_master_model_container: 8
2025-11-11 23:52:14,105:INFO:_display_container: 2
2025-11-11 23:52:14,107:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-11 23:52:14,108:INFO:create_model() successfully completed......................................
2025-11-11 23:52:14,252:INFO:SubProcess create_model() end ==================================
2025-11-11 23:52:14,252:INFO:Creating metrics dataframe
2025-11-11 23:52:14,259:INFO:Initializing Linear Discriminant Analysis
2025-11-11 23:52:14,259:INFO:Total runtime is 0.3043730099995931 minutes
2025-11-11 23:52:14,259:INFO:SubProcess create_model() called ==================================
2025-11-11 23:52:14,260:INFO:Initializing create_model()
2025-11-11 23:52:14,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6FE4ABE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:52:14,260:INFO:Checking exceptions
2025-11-11 23:52:14,260:INFO:Importing libraries
2025-11-11 23:52:14,260:INFO:Copying training dataset
2025-11-11 23:52:14,278:INFO:Defining folds
2025-11-11 23:52:14,279:INFO:Declaring metric variables
2025-11-11 23:52:14,280:INFO:Importing untrained model
2025-11-11 23:52:14,280:INFO:Linear Discriminant Analysis Imported successfully
2025-11-11 23:52:14,280:INFO:Starting cross validation
2025-11-11 23:52:14,284:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:52:14,710:INFO:Calculating mean and std
2025-11-11 23:52:14,712:INFO:Creating metrics dataframe
2025-11-11 23:52:14,719:INFO:Uploading results into container
2025-11-11 23:52:14,720:INFO:Uploading model into container now
2025-11-11 23:52:14,720:INFO:_master_model_container: 9
2025-11-11 23:52:14,720:INFO:_display_container: 2
2025-11-11 23:52:14,721:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-11 23:52:14,721:INFO:create_model() successfully completed......................................
2025-11-11 23:52:14,859:INFO:SubProcess create_model() end ==================================
2025-11-11 23:52:14,859:INFO:Creating metrics dataframe
2025-11-11 23:52:14,866:INFO:Initializing Extra Trees Classifier
2025-11-11 23:52:14,866:INFO:Total runtime is 0.31449198722839355 minutes
2025-11-11 23:52:14,866:INFO:SubProcess create_model() called ==================================
2025-11-11 23:52:14,866:INFO:Initializing create_model()
2025-11-11 23:52:14,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6FE4ABE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:52:14,866:INFO:Checking exceptions
2025-11-11 23:52:14,866:INFO:Importing libraries
2025-11-11 23:52:14,866:INFO:Copying training dataset
2025-11-11 23:52:14,886:INFO:Defining folds
2025-11-11 23:52:14,887:INFO:Declaring metric variables
2025-11-11 23:52:14,888:INFO:Importing untrained model
2025-11-11 23:52:14,888:INFO:Extra Trees Classifier Imported successfully
2025-11-11 23:52:14,890:INFO:Starting cross validation
2025-11-11 23:52:14,893:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:52:16,587:INFO:Calculating mean and std
2025-11-11 23:52:16,590:INFO:Creating metrics dataframe
2025-11-11 23:52:16,595:INFO:Uploading results into container
2025-11-11 23:52:16,595:INFO:Uploading model into container now
2025-11-11 23:52:16,597:INFO:_master_model_container: 10
2025-11-11 23:52:16,597:INFO:_display_container: 2
2025-11-11 23:52:16,597:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-11-11 23:52:16,597:INFO:create_model() successfully completed......................................
2025-11-11 23:52:16,727:INFO:SubProcess create_model() end ==================================
2025-11-11 23:52:16,727:INFO:Creating metrics dataframe
2025-11-11 23:52:16,734:INFO:Initializing Light Gradient Boosting Machine
2025-11-11 23:52:16,734:INFO:Total runtime is 0.345625102519989 minutes
2025-11-11 23:52:16,734:INFO:SubProcess create_model() called ==================================
2025-11-11 23:52:16,734:INFO:Initializing create_model()
2025-11-11 23:52:16,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6FE4ABE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:52:16,734:INFO:Checking exceptions
2025-11-11 23:52:16,735:INFO:Importing libraries
2025-11-11 23:52:16,735:INFO:Copying training dataset
2025-11-11 23:52:16,752:INFO:Defining folds
2025-11-11 23:52:16,753:INFO:Declaring metric variables
2025-11-11 23:52:16,753:INFO:Importing untrained model
2025-11-11 23:52:16,754:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-11 23:52:16,754:INFO:Starting cross validation
2025-11-11 23:52:16,759:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-11 23:52:38,707:INFO:Calculating mean and std
2025-11-11 23:52:38,711:INFO:Creating metrics dataframe
2025-11-11 23:52:38,715:INFO:Uploading results into container
2025-11-11 23:52:38,717:INFO:Uploading model into container now
2025-11-11 23:52:38,717:INFO:_master_model_container: 11
2025-11-11 23:52:38,717:INFO:_display_container: 2
2025-11-11 23:52:38,719:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-11 23:52:38,719:INFO:create_model() successfully completed......................................
2025-11-11 23:52:38,855:INFO:SubProcess create_model() end ==================================
2025-11-11 23:52:38,855:INFO:Creating metrics dataframe
2025-11-11 23:52:38,864:INFO:Initializing create_model()
2025-11-11 23:52:38,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-11 23:52:38,864:INFO:Checking exceptions
2025-11-11 23:52:38,866:INFO:Importing libraries
2025-11-11 23:52:38,866:INFO:Copying training dataset
2025-11-11 23:52:38,882:INFO:Defining folds
2025-11-11 23:52:38,882:INFO:Declaring metric variables
2025-11-11 23:52:38,882:INFO:Importing untrained model
2025-11-11 23:52:38,882:INFO:Declaring custom model
2025-11-11 23:52:38,885:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-11 23:52:38,889:INFO:Cross validation set to False
2025-11-11 23:52:38,889:INFO:Fitting Model
2025-11-11 23:52:39,096:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-11 23:52:39,102:INFO:[LightGBM] [Info] Number of positive: 1139, number of negative: 5949
2025-11-11 23:52:39,107:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002376 seconds.
2025-11-11 23:52:39,107:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-11 23:52:39,107:INFO:[LightGBM] [Info] Total Bins 2320
2025-11-11 23:52:39,109:INFO:[LightGBM] [Info] Number of data points in the train set: 7088, number of used features: 36
2025-11-11 23:52:39,110:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160694 -> initscore=-1.653072
2025-11-11 23:52:39,110:INFO:[LightGBM] [Info] Start training from score -1.653072
2025-11-11 23:52:41,844:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-11 23:52:41,846:INFO:create_model() successfully completed......................................
2025-11-11 23:52:42,010:INFO:_master_model_container: 11
2025-11-11 23:52:42,010:INFO:_display_container: 2
2025-11-11 23:52:42,012:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-11 23:52:42,012:INFO:compare_models() successfully completed......................................
2025-11-11 23:52:42,034:INFO:Initializing tune_model()
2025-11-11 23:52:42,035:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=30, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>)
2025-11-11 23:52:42,035:INFO:Checking exceptions
2025-11-11 23:52:42,048:INFO:Copying training dataset
2025-11-11 23:52:42,058:INFO:Checking base model
2025-11-11 23:52:42,058:INFO:Base model : Light Gradient Boosting Machine
2025-11-11 23:52:42,060:INFO:Declaring metric variables
2025-11-11 23:52:42,060:INFO:Defining Hyperparameters
2025-11-11 23:52:42,219:INFO:Tuning with n_jobs=-1
2025-11-11 23:52:42,219:INFO:Initializing RandomizedSearchCV
2025-11-12 00:01:17,194:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.2, 'actual_estimator__num_leaves': 40, 'actual_estimator__n_estimators': 160, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.4}
2025-11-12 00:01:17,200:INFO:Hyperparameter search completed
2025-11-12 00:01:17,202:INFO:SubProcess create_model() called ==================================
2025-11-12 00:01:17,205:INFO:Initializing create_model()
2025-11-12 00:01:17,205:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6FE69160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.2, 'num_leaves': 40, 'n_estimators': 160, 'min_split_gain': 0.4, 'min_child_samples': 6, 'learning_rate': 0.1, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.4})
2025-11-12 00:01:17,205:INFO:Checking exceptions
2025-11-12 00:01:17,205:INFO:Importing libraries
2025-11-12 00:01:17,205:INFO:Copying training dataset
2025-11-12 00:01:17,229:INFO:Defining folds
2025-11-12 00:01:17,230:INFO:Declaring metric variables
2025-11-12 00:01:17,231:INFO:Importing untrained model
2025-11-12 00:01:17,231:INFO:Declaring custom model
2025-11-12 00:01:17,234:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-12 00:01:17,234:INFO:Starting cross validation
2025-11-12 00:01:17,238:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 00:01:51,741:INFO:Calculating mean and std
2025-11-12 00:01:51,744:INFO:Creating metrics dataframe
2025-11-12 00:01:51,751:INFO:Finalizing model
2025-11-12 00:01:51,970:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-12 00:01:51,970:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-12 00:01:51,971:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-12 00:01:51,982:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-12 00:01:51,985:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-12 00:01:51,985:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-12 00:01:51,985:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-12 00:01:51,985:INFO:[LightGBM] [Info] Number of positive: 1139, number of negative: 5949
2025-11-12 00:01:51,994:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004774 seconds.
2025-11-12 00:01:51,995:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-11-12 00:01:51,995:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-11-12 00:01:51,995:INFO:[LightGBM] [Info] Total Bins 2322
2025-11-12 00:01:51,997:INFO:[LightGBM] [Info] Number of data points in the train set: 7088, number of used features: 37
2025-11-12 00:01:51,999:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160694 -> initscore=-1.653072
2025-11-12 00:01:51,999:INFO:[LightGBM] [Info] Start training from score -1.653072
2025-11-12 00:01:54,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:54,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:55,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:01:56,707:INFO:Uploading results into container
2025-11-12 00:01:56,709:INFO:Uploading model into container now
2025-11-12 00:01:56,710:INFO:_master_model_container: 12
2025-11-12 00:01:56,710:INFO:_display_container: 3
2025-11-12 00:01:56,712:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-12 00:01:56,712:INFO:create_model() successfully completed......................................
2025-11-12 00:01:56,956:INFO:SubProcess create_model() end ==================================
2025-11-12 00:01:56,957:INFO:choose_better activated
2025-11-12 00:01:56,957:INFO:SubProcess create_model() called ==================================
2025-11-12 00:01:56,959:INFO:Initializing create_model()
2025-11-12 00:01:56,959:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 00:01:56,959:INFO:Checking exceptions
2025-11-12 00:01:56,961:INFO:Importing libraries
2025-11-12 00:01:56,961:INFO:Copying training dataset
2025-11-12 00:01:56,986:INFO:Defining folds
2025-11-12 00:01:56,986:INFO:Declaring metric variables
2025-11-12 00:01:56,987:INFO:Importing untrained model
2025-11-12 00:01:56,987:INFO:Declaring custom model
2025-11-12 00:01:56,989:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-12 00:01:56,990:INFO:Starting cross validation
2025-11-12 00:01:56,993:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 00:02:31,276:INFO:Calculating mean and std
2025-11-12 00:02:31,278:INFO:Creating metrics dataframe
2025-11-12 00:02:31,281:INFO:Finalizing model
2025-11-12 00:02:31,483:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-12 00:02:31,484:INFO:[LightGBM] [Info] Number of positive: 1139, number of negative: 5949
2025-11-12 00:02:31,488:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002016 seconds.
2025-11-12 00:02:31,488:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-12 00:02:31,489:INFO:[LightGBM] [Info] Total Bins 2320
2025-11-12 00:02:31,489:INFO:[LightGBM] [Info] Number of data points in the train set: 7088, number of used features: 36
2025-11-12 00:02:31,489:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160694 -> initscore=-1.653072
2025-11-12 00:02:31,489:INFO:[LightGBM] [Info] Start training from score -1.653072
2025-11-12 00:02:34,324:INFO:Uploading results into container
2025-11-12 00:02:34,327:INFO:Uploading model into container now
2025-11-12 00:02:34,328:INFO:_master_model_container: 13
2025-11-12 00:02:34,328:INFO:_display_container: 4
2025-11-12 00:02:34,329:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-12 00:02:34,329:INFO:create_model() successfully completed......................................
2025-11-12 00:02:34,480:INFO:SubProcess create_model() end ==================================
2025-11-12 00:02:34,481:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8911
2025-11-12 00:02:34,482:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.892
2025-11-12 00:02:34,484:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-11-12 00:02:34,484:INFO:choose_better completed
2025-11-12 00:02:34,492:INFO:_master_model_container: 13
2025-11-12 00:02:34,493:INFO:_display_container: 3
2025-11-12 00:02:34,494:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-12 00:02:34,494:INFO:tune_model() successfully completed......................................
2025-11-12 00:02:34,636:INFO:Initializing finalize_model()
2025-11-12 00:02:34,636:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>, estimator=LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-11-12 00:02:34,637:INFO:Finalizing LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-12 00:02:34,651:INFO:Initializing create_model()
2025-11-12 00:02:34,651:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C278B80>, estimator=LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 00:02:34,652:INFO:Checking exceptions
2025-11-12 00:02:34,653:INFO:Importing libraries
2025-11-12 00:02:34,653:INFO:Copying training dataset
2025-11-12 00:02:34,655:INFO:Defining folds
2025-11-12 00:02:34,655:INFO:Declaring metric variables
2025-11-12 00:02:34,656:INFO:Importing untrained model
2025-11-12 00:02:34,656:INFO:Declaring custom model
2025-11-12 00:02:34,658:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-12 00:02:34,662:INFO:Cross validation set to False
2025-11-12 00:02:34,662:INFO:Fitting Model
2025-11-12 00:02:34,890:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-12 00:02:34,890:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-12 00:02:34,890:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-12 00:02:34,910:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-12 00:02:34,911:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-12 00:02:34,911:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-12 00:02:34,911:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-12 00:02:34,912:INFO:[LightGBM] [Info] Number of positive: 1627, number of negative: 8500
2025-11-12 00:02:34,918:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003876 seconds.
2025-11-12 00:02:34,918:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-11-12 00:02:34,918:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-11-12 00:02:34,918:INFO:[LightGBM] [Info] Total Bins 2324
2025-11-12 00:02:34,918:INFO:[LightGBM] [Info] Number of data points in the train set: 10127, number of used features: 37
2025-11-12 00:02:34,920:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160660 -> initscore=-1.653328
2025-11-12 00:02:34,920:INFO:[LightGBM] [Info] Start training from score -1.653328
2025-11-12 00:02:37,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:37,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:02:38,851:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-12 00:02:38,851:INFO:create_model() successfully completed......................................
2025-11-12 00:02:38,990:INFO:_master_model_container: 13
2025-11-12 00:02:38,990:INFO:_display_container: 3
2025-11-12 00:02:39,028:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-12 00:02:39,029:INFO:finalize_model() successfully completed......................................
2025-11-12 00:02:39,260:INFO:Initializing save_model()
2025-11-12 00:02:39,260:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=pycaret_best_automl_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\usuario\AppData\Local\Temp\2\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['education_level',
                                             'marital_status',
                                             'income_category',
                                             'card_category'],
                                    transformer=OneHotEncoder(cols=['education_level',
                                                                    'marital_status',
                                                                    'income_category',
                                                                    'card_category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-11-12 00:02:39,260:INFO:Adding model into prep_pipe
2025-11-12 00:02:39,260:WARNING:Only Model saved as it was a pipeline.
2025-11-12 00:02:39,296:INFO:pycaret_best_automl_model.pkl saved in current working directory
2025-11-12 00:02:39,339:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-12 00:02:39,339:INFO:save_model() successfully completed......................................
2025-11-12 00:02:39,497:INFO:Initializing load_model()
2025-11-12 00:02:39,497:INFO:load_model(model_name=pycaret_best_automl_model, platform=None, authentication=None, verbose=False)
2025-11-12 00:30:15,053:INFO:PyCaret ClassificationExperiment
2025-11-12 00:30:15,053:INFO:Logging name: clf-default-name
2025-11-12 00:30:15,053:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-12 00:30:15,053:INFO:version 3.3.2
2025-11-12 00:30:15,053:INFO:Initializing setup()
2025-11-12 00:30:15,053:INFO:self.USI: c190
2025-11-12 00:30:15,053:INFO:self._variable_keys: {'fold_generator', 'log_plots_param', 'html_param', 'X', 'fold_shuffle_param', 'gpu_param', 'X_test', 'memory', 'is_multiclass', 'seed', 'target_param', 'X_train', 'y_train', 'exp_id', 'fold_groups_param', 'idx', 'n_jobs_param', 'exp_name_log', 'data', '_ml_usecase', 'y_test', '_available_plots', 'y', 'gpu_n_jobs_param', 'fix_imbalance', 'USI', 'logging_param', 'pipeline'}
2025-11-12 00:30:15,053:INFO:Checking environment
2025-11-12 00:30:15,053:INFO:python_version: 3.9.10
2025-11-12 00:30:15,053:INFO:python_build: ('tags/v3.9.10:f2f3f53', 'Jan 17 2022 15:14:21')
2025-11-12 00:30:15,053:INFO:machine: AMD64
2025-11-12 00:30:15,053:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-12 00:30:15,059:INFO:Memory: svmem(total=42001428480, available=28573089792, percent=32.0, used=13428338688, free=28573089792)
2025-11-12 00:30:15,059:INFO:Physical Core: 16
2025-11-12 00:30:15,059:INFO:Logical Core: 16
2025-11-12 00:30:15,059:INFO:Checking libraries
2025-11-12 00:30:15,059:INFO:System:
2025-11-12 00:30:15,060:INFO:    python: 3.9.10 (tags/v3.9.10:f2f3f53, Jan 17 2022, 15:14:21) [MSC v.1929 64 bit (AMD64)]
2025-11-12 00:30:15,060:INFO:executable: C:\Users\usuario\PycharmProjects\PythonProject\.venv\Scripts\python.exe
2025-11-12 00:30:15,060:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-12 00:30:15,060:INFO:PyCaret required dependencies:
2025-11-12 00:30:15,061:INFO:                 pip: 25.3
2025-11-12 00:30:15,061:INFO:          setuptools: 80.3.1
2025-11-12 00:30:15,061:INFO:             pycaret: 3.3.2
2025-11-12 00:30:15,061:INFO:             IPython: 8.18.1
2025-11-12 00:30:15,061:INFO:          ipywidgets: 8.1.8
2025-11-12 00:30:15,061:INFO:                tqdm: 4.67.1
2025-11-12 00:30:15,061:INFO:               numpy: 1.26.4
2025-11-12 00:30:15,062:INFO:              pandas: 2.1.4
2025-11-12 00:30:15,062:INFO:              jinja2: 3.1.6
2025-11-12 00:30:15,062:INFO:               scipy: 1.11.4
2025-11-12 00:30:15,062:INFO:              joblib: 1.3.2
2025-11-12 00:30:15,062:INFO:             sklearn: 1.4.2
2025-11-12 00:30:15,062:INFO:                pyod: 2.0.5
2025-11-12 00:30:15,062:INFO:            imblearn: 0.12.4
2025-11-12 00:30:15,062:INFO:   category_encoders: 2.6.4
2025-11-12 00:30:15,062:INFO:            lightgbm: 4.6.0
2025-11-12 00:30:15,063:INFO:               numba: 0.60.0
2025-11-12 00:30:15,063:INFO:            requests: 2.32.5
2025-11-12 00:30:15,063:INFO:          matplotlib: 3.7.5
2025-11-12 00:30:15,063:INFO:          scikitplot: 0.3.7
2025-11-12 00:30:15,063:INFO:         yellowbrick: 1.5
2025-11-12 00:30:15,063:INFO:              plotly: 6.4.0
2025-11-12 00:30:15,063:INFO:    plotly-resampler: Not installed
2025-11-12 00:30:15,064:INFO:             kaleido: 1.2.0
2025-11-12 00:30:15,064:INFO:           schemdraw: 0.15
2025-11-12 00:30:15,064:INFO:         statsmodels: 0.14.5
2025-11-12 00:30:15,064:INFO:              sktime: 0.26.0
2025-11-12 00:30:15,064:INFO:               tbats: 1.1.3
2025-11-12 00:30:15,064:INFO:            pmdarima: 2.0.4
2025-11-12 00:30:15,064:INFO:              psutil: 7.1.3
2025-11-12 00:30:15,064:INFO:          markupsafe: 3.0.3
2025-11-12 00:30:15,065:INFO:             pickle5: Not installed
2025-11-12 00:30:15,065:INFO:         cloudpickle: 3.1.2
2025-11-12 00:30:15,065:INFO:         deprecation: 2.1.0
2025-11-12 00:30:15,065:INFO:              xxhash: 3.6.0
2025-11-12 00:30:15,065:INFO:           wurlitzer: Not installed
2025-11-12 00:30:15,065:INFO:PyCaret optional dependencies:
2025-11-12 00:30:15,065:INFO:                shap: Not installed
2025-11-12 00:30:15,066:INFO:           interpret: Not installed
2025-11-12 00:30:15,066:INFO:                umap: Not installed
2025-11-12 00:30:15,066:INFO:     ydata_profiling: Not installed
2025-11-12 00:30:15,066:INFO:  explainerdashboard: Not installed
2025-11-12 00:30:15,066:INFO:             autoviz: Not installed
2025-11-12 00:30:15,066:INFO:           fairlearn: Not installed
2025-11-12 00:30:15,066:INFO:          deepchecks: Not installed
2025-11-12 00:30:15,066:INFO:             xgboost: Not installed
2025-11-12 00:30:15,067:INFO:            catboost: Not installed
2025-11-12 00:30:15,067:INFO:              kmodes: Not installed
2025-11-12 00:30:15,067:INFO:             mlxtend: Not installed
2025-11-12 00:30:15,067:INFO:       statsforecast: Not installed
2025-11-12 00:30:15,067:INFO:        tune_sklearn: Not installed
2025-11-12 00:30:15,067:INFO:                 ray: Not installed
2025-11-12 00:30:15,067:INFO:            hyperopt: Not installed
2025-11-12 00:30:15,067:INFO:              optuna: Not installed
2025-11-12 00:30:15,067:INFO:               skopt: Not installed
2025-11-12 00:30:15,067:INFO:              mlflow: Not installed
2025-11-12 00:30:15,067:INFO:              gradio: Not installed
2025-11-12 00:30:15,068:INFO:             fastapi: Not installed
2025-11-12 00:30:15,068:INFO:             uvicorn: Not installed
2025-11-12 00:30:15,068:INFO:              m2cgen: Not installed
2025-11-12 00:30:15,068:INFO:           evidently: Not installed
2025-11-12 00:30:15,068:INFO:               fugue: Not installed
2025-11-12 00:30:15,068:INFO:           streamlit: Not installed
2025-11-12 00:30:15,069:INFO:             prophet: Not installed
2025-11-12 00:30:15,069:INFO:None
2025-11-12 00:30:15,069:INFO:Set up data.
2025-11-12 00:30:15,094:INFO:Set up folding strategy.
2025-11-12 00:30:15,094:INFO:Set up train/test split.
2025-11-12 00:30:15,113:INFO:Set up index.
2025-11-12 00:30:15,115:INFO:Assigning column types.
2025-11-12 00:30:15,127:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-12 00:30:15,197:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-12 00:30:15,198:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-12 00:30:15,240:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 00:30:15,242:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 00:30:15,320:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-12 00:30:15,322:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-12 00:30:15,372:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 00:30:15,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 00:30:15,373:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-12 00:30:15,449:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-12 00:30:15,497:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 00:30:15,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 00:30:15,569:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-12 00:30:15,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 00:30:15,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 00:30:15,619:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-12 00:30:15,737:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 00:30:15,737:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 00:30:15,863:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 00:30:15,863:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 00:30:15,866:INFO:Preparing preprocessing pipeline...
2025-11-12 00:30:15,870:INFO:Set up simple imputation.
2025-11-12 00:30:15,882:INFO:Set up encoding of ordinal features.
2025-11-12 00:30:15,890:INFO:Set up encoding of categorical features.
2025-11-12 00:30:16,156:INFO:Finished creating preprocessing pipeline.
2025-11-12 00:30:16,191:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\usuario\AppData\Local\Temp\2\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['education_level',
                                             'marital_status',
                                             'income_category',
                                             'card_category'],
                                    transformer=OneHotEncoder(cols=['education_level',
                                                                    'marital_status',
                                                                    'income_category',
                                                                    'card_category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-11-12 00:30:16,191:INFO:Creating final display dataframe.
2025-11-12 00:30:16,433:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target    attrition_flag
2                   Target type            Binary
3           Original data shape       (10127, 21)
4        Transformed data shape       (10127, 38)
5   Transformed train set shape        (7088, 38)
6    Transformed test set shape        (3039, 38)
7              Numeric features                15
8          Categorical features                 5
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              c190
2025-11-12 00:30:16,551:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 00:30:16,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 00:30:16,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 00:30:16,674:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 00:30:16,677:INFO:setup() successfully completed in 1.64s...............
2025-11-12 00:30:16,677:INFO:Initializing compare_models()
2025-11-12 00:30:16,677:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>, include=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>, 'include': None, 'exclude': ['ridge', 'dummy', 'svm', 'quadratic_discriminant_analysis'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['ridge', 'dummy', 'svm', 'quadratic_discriminant_analysis'])
2025-11-12 00:30:16,677:INFO:Checking exceptions
2025-11-12 00:30:16,692:INFO:Preparing display monitor
2025-11-12 00:30:16,697:INFO:Initializing Logistic Regression
2025-11-12 00:30:16,699:INFO:Total runtime is 3.299713134765625e-05 minutes
2025-11-12 00:30:16,699:INFO:SubProcess create_model() called ==================================
2025-11-12 00:30:16,699:INFO:Initializing create_model()
2025-11-12 00:30:16,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6C3A7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 00:30:16,699:INFO:Checking exceptions
2025-11-12 00:30:16,699:INFO:Importing libraries
2025-11-12 00:30:16,701:INFO:Copying training dataset
2025-11-12 00:30:16,718:INFO:Defining folds
2025-11-12 00:30:16,718:INFO:Declaring metric variables
2025-11-12 00:30:16,719:INFO:Importing untrained model
2025-11-12 00:30:16,719:INFO:Logistic Regression Imported successfully
2025-11-12 00:30:16,720:INFO:Starting cross validation
2025-11-12 00:30:16,724:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 00:30:19,863:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 00:30:19,896:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 00:30:20,031:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 00:30:20,134:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 00:30:20,207:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 00:30:20,262:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 00:30:20,359:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 00:30:20,365:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 00:30:20,369:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 00:30:20,382:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 00:30:20,606:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 00:30:20,949:INFO:Calculating mean and std
2025-11-12 00:30:20,953:INFO:Creating metrics dataframe
2025-11-12 00:30:20,957:INFO:Uploading results into container
2025-11-12 00:30:20,958:INFO:Uploading model into container now
2025-11-12 00:30:20,960:INFO:_master_model_container: 1
2025-11-12 00:30:20,960:INFO:_display_container: 2
2025-11-12 00:30:20,960:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-12 00:30:20,960:INFO:create_model() successfully completed......................................
2025-11-12 00:30:21,141:INFO:SubProcess create_model() end ==================================
2025-11-12 00:30:21,141:INFO:Creating metrics dataframe
2025-11-12 00:30:21,146:INFO:Initializing K Neighbors Classifier
2025-11-12 00:30:21,146:INFO:Total runtime is 0.07414654095967611 minutes
2025-11-12 00:30:21,147:INFO:SubProcess create_model() called ==================================
2025-11-12 00:30:21,147:INFO:Initializing create_model()
2025-11-12 00:30:21,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6C3A7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 00:30:21,148:INFO:Checking exceptions
2025-11-12 00:30:21,148:INFO:Importing libraries
2025-11-12 00:30:21,148:INFO:Copying training dataset
2025-11-12 00:30:21,174:INFO:Defining folds
2025-11-12 00:30:21,174:INFO:Declaring metric variables
2025-11-12 00:30:21,174:INFO:Importing untrained model
2025-11-12 00:30:21,176:INFO:K Neighbors Classifier Imported successfully
2025-11-12 00:30:21,177:INFO:Starting cross validation
2025-11-12 00:30:21,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 00:30:24,143:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 00:30:24,326:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 00:30:24,329:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 00:30:24,353:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 00:30:24,384:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 00:30:24,440:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 00:30:25,309:INFO:Calculating mean and std
2025-11-12 00:30:25,311:INFO:Creating metrics dataframe
2025-11-12 00:30:25,315:INFO:Uploading results into container
2025-11-12 00:30:25,317:INFO:Uploading model into container now
2025-11-12 00:30:25,317:INFO:_master_model_container: 2
2025-11-12 00:30:25,317:INFO:_display_container: 2
2025-11-12 00:30:25,319:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-12 00:30:25,319:INFO:create_model() successfully completed......................................
2025-11-12 00:30:25,480:INFO:SubProcess create_model() end ==================================
2025-11-12 00:30:25,480:INFO:Creating metrics dataframe
2025-11-12 00:30:25,486:INFO:Initializing Naive Bayes
2025-11-12 00:30:25,486:INFO:Total runtime is 0.14649521907170615 minutes
2025-11-12 00:30:25,486:INFO:SubProcess create_model() called ==================================
2025-11-12 00:30:25,486:INFO:Initializing create_model()
2025-11-12 00:30:25,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6C3A7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 00:30:25,486:INFO:Checking exceptions
2025-11-12 00:30:25,488:INFO:Importing libraries
2025-11-12 00:30:25,488:INFO:Copying training dataset
2025-11-12 00:30:25,508:INFO:Defining folds
2025-11-12 00:30:25,508:INFO:Declaring metric variables
2025-11-12 00:30:25,509:INFO:Importing untrained model
2025-11-12 00:30:25,509:INFO:Naive Bayes Imported successfully
2025-11-12 00:30:25,510:INFO:Starting cross validation
2025-11-12 00:30:25,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 00:30:25,856:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 00:30:25,860:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 00:30:25,871:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 00:30:25,873:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 00:30:25,881:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 00:30:25,888:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 00:30:25,891:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 00:30:25,892:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 00:30:25,894:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 00:30:25,900:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 00:30:25,918:INFO:Calculating mean and std
2025-11-12 00:30:25,922:INFO:Creating metrics dataframe
2025-11-12 00:30:25,927:INFO:Uploading results into container
2025-11-12 00:30:25,928:INFO:Uploading model into container now
2025-11-12 00:30:25,929:INFO:_master_model_container: 3
2025-11-12 00:30:25,929:INFO:_display_container: 2
2025-11-12 00:30:25,930:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-12 00:30:25,930:INFO:create_model() successfully completed......................................
2025-11-12 00:30:26,075:INFO:SubProcess create_model() end ==================================
2025-11-12 00:30:26,075:INFO:Creating metrics dataframe
2025-11-12 00:30:26,082:INFO:Initializing Decision Tree Classifier
2025-11-12 00:30:26,082:INFO:Total runtime is 0.15641274452209475 minutes
2025-11-12 00:30:26,082:INFO:SubProcess create_model() called ==================================
2025-11-12 00:30:26,082:INFO:Initializing create_model()
2025-11-12 00:30:26,082:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6C3A7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 00:30:26,082:INFO:Checking exceptions
2025-11-12 00:30:26,082:INFO:Importing libraries
2025-11-12 00:30:26,082:INFO:Copying training dataset
2025-11-12 00:30:26,101:INFO:Defining folds
2025-11-12 00:30:26,103:INFO:Declaring metric variables
2025-11-12 00:30:26,104:INFO:Importing untrained model
2025-11-12 00:30:26,104:INFO:Decision Tree Classifier Imported successfully
2025-11-12 00:30:26,105:INFO:Starting cross validation
2025-11-12 00:30:26,108:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 00:30:26,619:INFO:Calculating mean and std
2025-11-12 00:30:26,624:INFO:Creating metrics dataframe
2025-11-12 00:30:26,628:INFO:Uploading results into container
2025-11-12 00:30:26,629:INFO:Uploading model into container now
2025-11-12 00:30:26,630:INFO:_master_model_container: 4
2025-11-12 00:30:26,630:INFO:_display_container: 2
2025-11-12 00:30:26,631:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-11-12 00:30:26,631:INFO:create_model() successfully completed......................................
2025-11-12 00:30:26,804:INFO:SubProcess create_model() end ==================================
2025-11-12 00:30:26,805:INFO:Creating metrics dataframe
2025-11-12 00:30:26,812:INFO:Initializing Random Forest Classifier
2025-11-12 00:30:26,812:INFO:Total runtime is 0.16858363946278893 minutes
2025-11-12 00:30:26,812:INFO:SubProcess create_model() called ==================================
2025-11-12 00:30:26,812:INFO:Initializing create_model()
2025-11-12 00:30:26,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6C3A7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 00:30:26,812:INFO:Checking exceptions
2025-11-12 00:30:26,812:INFO:Importing libraries
2025-11-12 00:30:26,812:INFO:Copying training dataset
2025-11-12 00:30:26,834:INFO:Defining folds
2025-11-12 00:30:26,834:INFO:Declaring metric variables
2025-11-12 00:30:26,834:INFO:Importing untrained model
2025-11-12 00:30:26,834:INFO:Random Forest Classifier Imported successfully
2025-11-12 00:30:26,836:INFO:Starting cross validation
2025-11-12 00:30:26,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 00:30:28,880:INFO:Calculating mean and std
2025-11-12 00:30:28,884:INFO:Creating metrics dataframe
2025-11-12 00:30:28,888:INFO:Uploading results into container
2025-11-12 00:30:28,889:INFO:Uploading model into container now
2025-11-12 00:30:28,890:INFO:_master_model_container: 5
2025-11-12 00:30:28,891:INFO:_display_container: 2
2025-11-12 00:30:28,891:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-11-12 00:30:28,891:INFO:create_model() successfully completed......................................
2025-11-12 00:30:29,039:INFO:SubProcess create_model() end ==================================
2025-11-12 00:30:29,039:INFO:Creating metrics dataframe
2025-11-12 00:30:29,045:INFO:Initializing Quadratic Discriminant Analysis
2025-11-12 00:30:29,045:INFO:Total runtime is 0.20580637852350875 minutes
2025-11-12 00:30:29,045:INFO:SubProcess create_model() called ==================================
2025-11-12 00:30:29,045:INFO:Initializing create_model()
2025-11-12 00:30:29,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6C3A7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 00:30:29,047:INFO:Checking exceptions
2025-11-12 00:30:29,047:INFO:Importing libraries
2025-11-12 00:30:29,047:INFO:Copying training dataset
2025-11-12 00:30:29,068:INFO:Defining folds
2025-11-12 00:30:29,068:INFO:Declaring metric variables
2025-11-12 00:30:29,068:INFO:Importing untrained model
2025-11-12 00:30:29,068:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-12 00:30:29,069:INFO:Starting cross validation
2025-11-12 00:30:29,072:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 00:30:29,336:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-12 00:30:29,345:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-12 00:30:29,347:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-12 00:30:29,349:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-12 00:30:29,352:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-12 00:30:29,370:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-12 00:30:29,384:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-12 00:30:29,390:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-12 00:30:29,407:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-12 00:30:29,521:INFO:Calculating mean and std
2025-11-12 00:30:29,525:INFO:Creating metrics dataframe
2025-11-12 00:30:29,529:INFO:Uploading results into container
2025-11-12 00:30:29,530:INFO:Uploading model into container now
2025-11-12 00:30:29,532:INFO:_master_model_container: 6
2025-11-12 00:30:29,532:INFO:_display_container: 2
2025-11-12 00:30:29,533:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-12 00:30:29,534:INFO:create_model() successfully completed......................................
2025-11-12 00:30:29,701:INFO:SubProcess create_model() end ==================================
2025-11-12 00:30:29,701:INFO:Creating metrics dataframe
2025-11-12 00:30:29,705:INFO:Initializing Ada Boost Classifier
2025-11-12 00:30:29,705:INFO:Total runtime is 0.2168110330899557 minutes
2025-11-12 00:30:29,708:INFO:SubProcess create_model() called ==================================
2025-11-12 00:30:29,708:INFO:Initializing create_model()
2025-11-12 00:30:29,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6C3A7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 00:30:29,708:INFO:Checking exceptions
2025-11-12 00:30:29,708:INFO:Importing libraries
2025-11-12 00:30:29,708:INFO:Copying training dataset
2025-11-12 00:30:29,729:INFO:Defining folds
2025-11-12 00:30:29,729:INFO:Declaring metric variables
2025-11-12 00:30:29,729:INFO:Importing untrained model
2025-11-12 00:30:29,730:INFO:Ada Boost Classifier Imported successfully
2025-11-12 00:30:29,731:INFO:Starting cross validation
2025-11-12 00:30:29,735:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 00:30:29,969:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 00:30:29,976:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 00:30:29,976:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 00:30:29,991:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 00:30:29,993:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 00:30:29,993:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 00:30:29,997:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 00:30:30,004:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 00:30:30,017:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 00:30:30,021:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 00:30:30,960:INFO:Calculating mean and std
2025-11-12 00:30:30,963:INFO:Creating metrics dataframe
2025-11-12 00:30:30,967:INFO:Uploading results into container
2025-11-12 00:30:30,969:INFO:Uploading model into container now
2025-11-12 00:30:30,969:INFO:_master_model_container: 7
2025-11-12 00:30:30,969:INFO:_display_container: 2
2025-11-12 00:30:30,969:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-11-12 00:30:30,969:INFO:create_model() successfully completed......................................
2025-11-12 00:30:31,124:INFO:SubProcess create_model() end ==================================
2025-11-12 00:30:31,126:INFO:Creating metrics dataframe
2025-11-12 00:30:31,131:INFO:Initializing Gradient Boosting Classifier
2025-11-12 00:30:31,131:INFO:Total runtime is 0.240569818019867 minutes
2025-11-12 00:30:31,131:INFO:SubProcess create_model() called ==================================
2025-11-12 00:30:31,131:INFO:Initializing create_model()
2025-11-12 00:30:31,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6C3A7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 00:30:31,133:INFO:Checking exceptions
2025-11-12 00:30:31,133:INFO:Importing libraries
2025-11-12 00:30:31,133:INFO:Copying training dataset
2025-11-12 00:30:31,154:INFO:Defining folds
2025-11-12 00:30:31,154:INFO:Declaring metric variables
2025-11-12 00:30:31,154:INFO:Importing untrained model
2025-11-12 00:30:31,154:INFO:Gradient Boosting Classifier Imported successfully
2025-11-12 00:30:31,154:INFO:Starting cross validation
2025-11-12 00:30:31,160:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 00:30:34,699:INFO:Calculating mean and std
2025-11-12 00:30:34,703:INFO:Creating metrics dataframe
2025-11-12 00:30:34,707:INFO:Uploading results into container
2025-11-12 00:30:34,708:INFO:Uploading model into container now
2025-11-12 00:30:34,708:INFO:_master_model_container: 8
2025-11-12 00:30:34,708:INFO:_display_container: 2
2025-11-12 00:30:34,709:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-12 00:30:34,709:INFO:create_model() successfully completed......................................
2025-11-12 00:30:34,873:INFO:SubProcess create_model() end ==================================
2025-11-12 00:30:34,873:INFO:Creating metrics dataframe
2025-11-12 00:30:34,879:INFO:Initializing Linear Discriminant Analysis
2025-11-12 00:30:34,879:INFO:Total runtime is 0.30303116242090866 minutes
2025-11-12 00:30:34,879:INFO:SubProcess create_model() called ==================================
2025-11-12 00:30:34,880:INFO:Initializing create_model()
2025-11-12 00:30:34,880:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6C3A7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 00:30:34,880:INFO:Checking exceptions
2025-11-12 00:30:34,880:INFO:Importing libraries
2025-11-12 00:30:34,880:INFO:Copying training dataset
2025-11-12 00:30:34,903:INFO:Defining folds
2025-11-12 00:30:34,903:INFO:Declaring metric variables
2025-11-12 00:30:34,904:INFO:Importing untrained model
2025-11-12 00:30:34,904:INFO:Linear Discriminant Analysis Imported successfully
2025-11-12 00:30:34,905:INFO:Starting cross validation
2025-11-12 00:30:34,910:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 00:30:35,337:INFO:Calculating mean and std
2025-11-12 00:30:35,341:INFO:Creating metrics dataframe
2025-11-12 00:30:35,345:INFO:Uploading results into container
2025-11-12 00:30:35,346:INFO:Uploading model into container now
2025-11-12 00:30:35,346:INFO:_master_model_container: 9
2025-11-12 00:30:35,346:INFO:_display_container: 2
2025-11-12 00:30:35,347:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-12 00:30:35,347:INFO:create_model() successfully completed......................................
2025-11-12 00:30:35,479:INFO:SubProcess create_model() end ==================================
2025-11-12 00:30:35,480:INFO:Creating metrics dataframe
2025-11-12 00:30:35,485:INFO:Initializing Extra Trees Classifier
2025-11-12 00:30:35,485:INFO:Total runtime is 0.3131321628888449 minutes
2025-11-12 00:30:35,485:INFO:SubProcess create_model() called ==================================
2025-11-12 00:30:35,485:INFO:Initializing create_model()
2025-11-12 00:30:35,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6C3A7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 00:30:35,486:INFO:Checking exceptions
2025-11-12 00:30:35,486:INFO:Importing libraries
2025-11-12 00:30:35,486:INFO:Copying training dataset
2025-11-12 00:30:35,502:INFO:Defining folds
2025-11-12 00:30:35,504:INFO:Declaring metric variables
2025-11-12 00:30:35,504:INFO:Importing untrained model
2025-11-12 00:30:35,504:INFO:Extra Trees Classifier Imported successfully
2025-11-12 00:30:35,506:INFO:Starting cross validation
2025-11-12 00:30:35,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 00:30:37,178:INFO:Calculating mean and std
2025-11-12 00:30:37,180:INFO:Creating metrics dataframe
2025-11-12 00:30:37,185:INFO:Uploading results into container
2025-11-12 00:30:37,187:INFO:Uploading model into container now
2025-11-12 00:30:37,188:INFO:_master_model_container: 10
2025-11-12 00:30:37,188:INFO:_display_container: 2
2025-11-12 00:30:37,188:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-11-12 00:30:37,188:INFO:create_model() successfully completed......................................
2025-11-12 00:30:37,345:INFO:SubProcess create_model() end ==================================
2025-11-12 00:30:37,345:INFO:Creating metrics dataframe
2025-11-12 00:30:37,350:INFO:Initializing Light Gradient Boosting Machine
2025-11-12 00:30:37,351:INFO:Total runtime is 0.34423773686091114 minutes
2025-11-12 00:30:37,351:INFO:SubProcess create_model() called ==================================
2025-11-12 00:30:37,352:INFO:Initializing create_model()
2025-11-12 00:30:37,352:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6C3A7940>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 00:30:37,352:INFO:Checking exceptions
2025-11-12 00:30:37,352:INFO:Importing libraries
2025-11-12 00:30:37,352:INFO:Copying training dataset
2025-11-12 00:30:37,373:INFO:Defining folds
2025-11-12 00:30:37,373:INFO:Declaring metric variables
2025-11-12 00:30:37,373:INFO:Importing untrained model
2025-11-12 00:30:37,375:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-12 00:30:37,375:INFO:Starting cross validation
2025-11-12 00:30:37,379:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 00:30:58,145:INFO:Calculating mean and std
2025-11-12 00:30:58,150:INFO:Creating metrics dataframe
2025-11-12 00:30:58,154:INFO:Uploading results into container
2025-11-12 00:30:58,156:INFO:Uploading model into container now
2025-11-12 00:30:58,156:INFO:_master_model_container: 11
2025-11-12 00:30:58,156:INFO:_display_container: 2
2025-11-12 00:30:58,156:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-12 00:30:58,158:INFO:create_model() successfully completed......................................
2025-11-12 00:30:58,347:INFO:SubProcess create_model() end ==================================
2025-11-12 00:30:58,347:INFO:Creating metrics dataframe
2025-11-12 00:30:58,361:INFO:Initializing create_model()
2025-11-12 00:30:58,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 00:30:58,362:INFO:Checking exceptions
2025-11-12 00:30:58,364:INFO:Importing libraries
2025-11-12 00:30:58,364:INFO:Copying training dataset
2025-11-12 00:30:58,387:INFO:Defining folds
2025-11-12 00:30:58,387:INFO:Declaring metric variables
2025-11-12 00:30:58,388:INFO:Importing untrained model
2025-11-12 00:30:58,388:INFO:Declaring custom model
2025-11-12 00:30:58,390:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-12 00:30:58,394:INFO:Cross validation set to False
2025-11-12 00:30:58,394:INFO:Fitting Model
2025-11-12 00:30:58,604:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-12 00:30:58,606:INFO:[LightGBM] [Info] Number of positive: 1139, number of negative: 5949
2025-11-12 00:30:58,611:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003220 seconds.
2025-11-12 00:30:58,611:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-11-12 00:30:58,611:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-11-12 00:30:58,611:INFO:[LightGBM] [Info] Total Bins 2320
2025-11-12 00:30:58,613:INFO:[LightGBM] [Info] Number of data points in the train set: 7088, number of used features: 36
2025-11-12 00:30:58,613:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160694 -> initscore=-1.653072
2025-11-12 00:30:58,614:INFO:[LightGBM] [Info] Start training from score -1.653072
2025-11-12 00:31:00,434:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-12 00:31:00,435:INFO:create_model() successfully completed......................................
2025-11-12 00:31:00,591:INFO:_master_model_container: 11
2025-11-12 00:31:00,591:INFO:_display_container: 2
2025-11-12 00:31:00,592:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-12 00:31:00,592:INFO:compare_models() successfully completed......................................
2025-11-12 00:31:00,613:INFO:Initializing tune_model()
2025-11-12 00:31:00,613:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=30, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>)
2025-11-12 00:31:00,613:INFO:Checking exceptions
2025-11-12 00:31:00,627:INFO:Copying training dataset
2025-11-12 00:31:00,639:INFO:Checking base model
2025-11-12 00:31:00,639:INFO:Base model : Light Gradient Boosting Machine
2025-11-12 00:31:00,639:INFO:Declaring metric variables
2025-11-12 00:31:00,640:INFO:Defining Hyperparameters
2025-11-12 00:31:00,797:INFO:Tuning with n_jobs=-1
2025-11-12 00:31:00,798:INFO:Initializing RandomizedSearchCV
2025-11-12 00:38:54,876:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.2, 'actual_estimator__num_leaves': 40, 'actual_estimator__n_estimators': 160, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.4}
2025-11-12 00:38:54,883:INFO:Hyperparameter search completed
2025-11-12 00:38:54,884:INFO:SubProcess create_model() called ==================================
2025-11-12 00:38:54,886:INFO:Initializing create_model()
2025-11-12 00:38:54,887:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE6C3A7580>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.2, 'num_leaves': 40, 'n_estimators': 160, 'min_split_gain': 0.4, 'min_child_samples': 6, 'learning_rate': 0.1, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.4})
2025-11-12 00:38:54,887:INFO:Checking exceptions
2025-11-12 00:38:54,888:INFO:Importing libraries
2025-11-12 00:38:54,888:INFO:Copying training dataset
2025-11-12 00:38:54,913:INFO:Defining folds
2025-11-12 00:38:54,913:INFO:Declaring metric variables
2025-11-12 00:38:54,915:INFO:Importing untrained model
2025-11-12 00:38:54,915:INFO:Declaring custom model
2025-11-12 00:38:54,917:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-12 00:38:54,919:INFO:Starting cross validation
2025-11-12 00:38:54,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 00:39:16,451:INFO:Calculating mean and std
2025-11-12 00:39:16,456:INFO:Creating metrics dataframe
2025-11-12 00:39:16,461:INFO:Finalizing model
2025-11-12 00:39:16,668:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-12 00:39:16,670:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-12 00:39:16,670:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-12 00:39:16,687:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-12 00:39:16,688:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-12 00:39:16,688:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-12 00:39:16,688:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-12 00:39:16,689:INFO:[LightGBM] [Info] Number of positive: 1139, number of negative: 5949
2025-11-12 00:39:16,694:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002720 seconds.
2025-11-12 00:39:16,694:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-11-12 00:39:16,694:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-11-12 00:39:16,694:INFO:[LightGBM] [Info] Total Bins 2322
2025-11-12 00:39:16,699:INFO:[LightGBM] [Info] Number of data points in the train set: 7088, number of used features: 37
2025-11-12 00:39:16,700:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160694 -> initscore=-1.653072
2025-11-12 00:39:16,700:INFO:[LightGBM] [Info] Start training from score -1.653072
2025-11-12 00:39:17,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:17,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:17,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:17,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:17,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:17,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:17,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:17,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:17,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:17,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:17,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:17,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:17,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:17,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:17,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:18,643:INFO:Uploading results into container
2025-11-12 00:39:18,645:INFO:Uploading model into container now
2025-11-12 00:39:18,646:INFO:_master_model_container: 12
2025-11-12 00:39:18,646:INFO:_display_container: 3
2025-11-12 00:39:18,647:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-12 00:39:18,647:INFO:create_model() successfully completed......................................
2025-11-12 00:39:18,893:INFO:SubProcess create_model() end ==================================
2025-11-12 00:39:18,893:INFO:choose_better activated
2025-11-12 00:39:18,894:INFO:SubProcess create_model() called ==================================
2025-11-12 00:39:18,896:INFO:Initializing create_model()
2025-11-12 00:39:18,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 00:39:18,896:INFO:Checking exceptions
2025-11-12 00:39:18,897:INFO:Importing libraries
2025-11-12 00:39:18,899:INFO:Copying training dataset
2025-11-12 00:39:18,917:INFO:Defining folds
2025-11-12 00:39:18,917:INFO:Declaring metric variables
2025-11-12 00:39:18,917:INFO:Importing untrained model
2025-11-12 00:39:18,917:INFO:Declaring custom model
2025-11-12 00:39:18,919:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-12 00:39:18,919:INFO:Starting cross validation
2025-11-12 00:39:18,923:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 00:39:53,623:INFO:Calculating mean and std
2025-11-12 00:39:53,624:INFO:Creating metrics dataframe
2025-11-12 00:39:53,627:INFO:Finalizing model
2025-11-12 00:39:53,825:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-12 00:39:53,826:INFO:[LightGBM] [Info] Number of positive: 1139, number of negative: 5949
2025-11-12 00:39:53,829:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001757 seconds.
2025-11-12 00:39:53,829:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-11-12 00:39:53,829:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-11-12 00:39:53,829:INFO:[LightGBM] [Info] Total Bins 2320
2025-11-12 00:39:53,831:INFO:[LightGBM] [Info] Number of data points in the train set: 7088, number of used features: 36
2025-11-12 00:39:53,831:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160694 -> initscore=-1.653072
2025-11-12 00:39:53,833:INFO:[LightGBM] [Info] Start training from score -1.653072
2025-11-12 00:39:55,001:INFO:Uploading results into container
2025-11-12 00:39:55,002:INFO:Uploading model into container now
2025-11-12 00:39:55,002:INFO:_master_model_container: 13
2025-11-12 00:39:55,003:INFO:_display_container: 4
2025-11-12 00:39:55,005:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-12 00:39:55,005:INFO:create_model() successfully completed......................................
2025-11-12 00:39:55,150:INFO:SubProcess create_model() end ==================================
2025-11-12 00:39:55,152:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8911
2025-11-12 00:39:55,153:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.892
2025-11-12 00:39:55,154:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-11-12 00:39:55,155:INFO:choose_better completed
2025-11-12 00:39:55,163:INFO:_master_model_container: 13
2025-11-12 00:39:55,163:INFO:_display_container: 3
2025-11-12 00:39:55,165:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-12 00:39:55,165:INFO:tune_model() successfully completed......................................
2025-11-12 00:39:55,291:INFO:Initializing finalize_model()
2025-11-12 00:39:55,292:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>, estimator=LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-11-12 00:39:55,293:INFO:Finalizing LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-12 00:39:55,302:INFO:Initializing create_model()
2025-11-12 00:39:55,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE71517220>, estimator=LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 00:39:55,303:INFO:Checking exceptions
2025-11-12 00:39:55,304:INFO:Importing libraries
2025-11-12 00:39:55,304:INFO:Copying training dataset
2025-11-12 00:39:55,304:INFO:Defining folds
2025-11-12 00:39:55,304:INFO:Declaring metric variables
2025-11-12 00:39:55,306:INFO:Importing untrained model
2025-11-12 00:39:55,306:INFO:Declaring custom model
2025-11-12 00:39:55,309:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-12 00:39:55,311:INFO:Cross validation set to False
2025-11-12 00:39:55,311:INFO:Fitting Model
2025-11-12 00:39:55,523:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-12 00:39:55,523:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-12 00:39:55,523:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-12 00:39:55,538:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-12 00:39:55,538:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-12 00:39:55,538:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-12 00:39:55,538:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-12 00:39:55,539:INFO:[LightGBM] [Info] Number of positive: 1627, number of negative: 8500
2025-11-12 00:39:55,542:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001517 seconds.
2025-11-12 00:39:55,542:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-11-12 00:39:55,542:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-11-12 00:39:55,542:INFO:[LightGBM] [Info] Total Bins 2324
2025-11-12 00:39:55,543:INFO:[LightGBM] [Info] Number of data points in the train set: 10127, number of used features: 37
2025-11-12 00:39:55,544:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160660 -> initscore=-1.653328
2025-11-12 00:39:55,544:INFO:[LightGBM] [Info] Start training from score -1.653328
2025-11-12 00:39:56,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:56,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:56,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:56,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:56,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:56,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:56,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:56,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:56,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:56,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:56,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:56,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:56,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 00:39:57,466:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-12 00:39:57,466:INFO:create_model() successfully completed......................................
2025-11-12 00:39:57,636:INFO:_master_model_container: 13
2025-11-12 00:39:57,636:INFO:_display_container: 3
2025-11-12 00:39:57,668:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-12 00:39:57,668:INFO:finalize_model() successfully completed......................................
2025-11-12 00:39:57,891:INFO:Initializing save_model()
2025-11-12 00:39:57,893:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=pycaret_best_automl_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\usuario\AppData\Local\Temp\2\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['education_level',
                                             'marital_status',
                                             'income_category',
                                             'card_category'],
                                    transformer=OneHotEncoder(cols=['education_level',
                                                                    'marital_status',
                                                                    'income_category',
                                                                    'card_category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-11-12 00:39:57,893:INFO:Adding model into prep_pipe
2025-11-12 00:39:57,893:WARNING:Only Model saved as it was a pipeline.
2025-11-12 00:39:57,927:INFO:pycaret_best_automl_model.pkl saved in current working directory
2025-11-12 00:39:57,965:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-12 00:39:57,965:INFO:save_model() successfully completed......................................
2025-11-12 00:39:58,106:INFO:Initializing load_model()
2025-11-12 00:39:58,106:INFO:load_model(model_name=pycaret_best_automl_model, platform=None, authentication=None, verbose=False)
2025-11-12 21:56:29,836:INFO:PyCaret ClassificationExperiment
2025-11-12 21:56:29,836:INFO:Logging name: clf-default-name
2025-11-12 21:56:29,836:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-11-12 21:56:29,836:INFO:version 3.3.2
2025-11-12 21:56:29,836:INFO:Initializing setup()
2025-11-12 21:56:29,836:INFO:self.USI: 04b1
2025-11-12 21:56:29,836:INFO:self._variable_keys: {'fold_generator', 'log_plots_param', 'html_param', 'X', 'fold_shuffle_param', 'gpu_param', 'X_test', 'memory', 'is_multiclass', 'seed', 'target_param', 'X_train', 'y_train', 'exp_id', 'fold_groups_param', 'idx', 'n_jobs_param', 'exp_name_log', 'data', '_ml_usecase', 'y_test', '_available_plots', 'y', 'gpu_n_jobs_param', 'fix_imbalance', 'USI', 'logging_param', 'pipeline'}
2025-11-12 21:56:29,836:INFO:Checking environment
2025-11-12 21:56:29,836:INFO:python_version: 3.9.10
2025-11-12 21:56:29,838:INFO:python_build: ('tags/v3.9.10:f2f3f53', 'Jan 17 2022 15:14:21')
2025-11-12 21:56:29,838:INFO:machine: AMD64
2025-11-12 21:56:29,838:INFO:platform: Windows-10-10.0.26100-SP0
2025-11-12 21:56:29,841:INFO:Memory: svmem(total=42001428480, available=28585394176, percent=31.9, used=13416034304, free=28585394176)
2025-11-12 21:56:29,841:INFO:Physical Core: 16
2025-11-12 21:56:29,843:INFO:Logical Core: 16
2025-11-12 21:56:29,843:INFO:Checking libraries
2025-11-12 21:56:29,843:INFO:System:
2025-11-12 21:56:29,843:INFO:    python: 3.9.10 (tags/v3.9.10:f2f3f53, Jan 17 2022, 15:14:21) [MSC v.1929 64 bit (AMD64)]
2025-11-12 21:56:29,843:INFO:executable: C:\Users\usuario\PycharmProjects\PythonProject\.venv\Scripts\python.exe
2025-11-12 21:56:29,843:INFO:   machine: Windows-10-10.0.26100-SP0
2025-11-12 21:56:29,843:INFO:PyCaret required dependencies:
2025-11-12 21:56:29,843:INFO:                 pip: 25.3
2025-11-12 21:56:29,843:INFO:          setuptools: 80.3.1
2025-11-12 21:56:29,843:INFO:             pycaret: 3.3.2
2025-11-12 21:56:29,843:INFO:             IPython: 8.18.1
2025-11-12 21:56:29,843:INFO:          ipywidgets: 8.1.8
2025-11-12 21:56:29,843:INFO:                tqdm: 4.67.1
2025-11-12 21:56:29,843:INFO:               numpy: 1.26.4
2025-11-12 21:56:29,843:INFO:              pandas: 2.1.4
2025-11-12 21:56:29,843:INFO:              jinja2: 3.1.6
2025-11-12 21:56:29,843:INFO:               scipy: 1.11.4
2025-11-12 21:56:29,845:INFO:              joblib: 1.3.2
2025-11-12 21:56:29,845:INFO:             sklearn: 1.4.2
2025-11-12 21:56:29,845:INFO:                pyod: 2.0.5
2025-11-12 21:56:29,845:INFO:            imblearn: 0.12.4
2025-11-12 21:56:29,845:INFO:   category_encoders: 2.6.4
2025-11-12 21:56:29,845:INFO:            lightgbm: 4.6.0
2025-11-12 21:56:29,845:INFO:               numba: 0.60.0
2025-11-12 21:56:29,845:INFO:            requests: 2.32.5
2025-11-12 21:56:29,845:INFO:          matplotlib: 3.7.5
2025-11-12 21:56:29,845:INFO:          scikitplot: 0.3.7
2025-11-12 21:56:29,845:INFO:         yellowbrick: 1.5
2025-11-12 21:56:29,845:INFO:              plotly: 6.4.0
2025-11-12 21:56:29,845:INFO:    plotly-resampler: Not installed
2025-11-12 21:56:29,845:INFO:             kaleido: 1.2.0
2025-11-12 21:56:29,845:INFO:           schemdraw: 0.15
2025-11-12 21:56:29,845:INFO:         statsmodels: 0.14.5
2025-11-12 21:56:29,845:INFO:              sktime: 0.26.0
2025-11-12 21:56:29,845:INFO:               tbats: 1.1.3
2025-11-12 21:56:29,845:INFO:            pmdarima: 2.0.4
2025-11-12 21:56:29,845:INFO:              psutil: 7.1.3
2025-11-12 21:56:29,845:INFO:          markupsafe: 3.0.3
2025-11-12 21:56:29,845:INFO:             pickle5: Not installed
2025-11-12 21:56:29,847:INFO:         cloudpickle: 3.1.2
2025-11-12 21:56:29,847:INFO:         deprecation: 2.1.0
2025-11-12 21:56:29,847:INFO:              xxhash: 3.6.0
2025-11-12 21:56:29,847:INFO:           wurlitzer: Not installed
2025-11-12 21:56:29,847:INFO:PyCaret optional dependencies:
2025-11-12 21:56:29,847:INFO:                shap: Not installed
2025-11-12 21:56:29,847:INFO:           interpret: Not installed
2025-11-12 21:56:29,847:INFO:                umap: Not installed
2025-11-12 21:56:29,847:INFO:     ydata_profiling: Not installed
2025-11-12 21:56:29,847:INFO:  explainerdashboard: Not installed
2025-11-12 21:56:29,847:INFO:             autoviz: Not installed
2025-11-12 21:56:29,847:INFO:           fairlearn: Not installed
2025-11-12 21:56:29,847:INFO:          deepchecks: Not installed
2025-11-12 21:56:29,847:INFO:             xgboost: Not installed
2025-11-12 21:56:29,847:INFO:            catboost: Not installed
2025-11-12 21:56:29,847:INFO:              kmodes: Not installed
2025-11-12 21:56:29,847:INFO:             mlxtend: Not installed
2025-11-12 21:56:29,847:INFO:       statsforecast: Not installed
2025-11-12 21:56:29,847:INFO:        tune_sklearn: Not installed
2025-11-12 21:56:29,847:INFO:                 ray: Not installed
2025-11-12 21:56:29,849:INFO:            hyperopt: Not installed
2025-11-12 21:56:29,849:INFO:              optuna: Not installed
2025-11-12 21:56:29,849:INFO:               skopt: Not installed
2025-11-12 21:56:29,849:INFO:              mlflow: Not installed
2025-11-12 21:56:29,849:INFO:              gradio: Not installed
2025-11-12 21:56:29,849:INFO:             fastapi: Not installed
2025-11-12 21:56:29,849:INFO:             uvicorn: Not installed
2025-11-12 21:56:29,849:INFO:              m2cgen: Not installed
2025-11-12 21:56:29,849:INFO:           evidently: Not installed
2025-11-12 21:56:29,849:INFO:               fugue: Not installed
2025-11-12 21:56:29,849:INFO:           streamlit: Not installed
2025-11-12 21:56:29,849:INFO:             prophet: Not installed
2025-11-12 21:56:29,849:INFO:None
2025-11-12 21:56:29,849:INFO:Set up data.
2025-11-12 21:56:29,874:INFO:Set up folding strategy.
2025-11-12 21:56:29,874:INFO:Set up train/test split.
2025-11-12 21:56:29,895:INFO:Set up index.
2025-11-12 21:56:29,895:INFO:Assigning column types.
2025-11-12 21:56:29,910:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-11-12 21:56:29,978:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-12 21:56:29,978:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-12 21:56:30,021:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 21:56:30,024:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 21:56:30,092:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-11-12 21:56:30,093:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-12 21:56:30,132:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 21:56:30,134:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 21:56:30,134:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-11-12 21:56:30,203:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-12 21:56:30,240:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 21:56:30,240:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 21:56:30,306:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-11-12 21:56:30,342:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 21:56:30,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 21:56:30,344:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-11-12 21:56:30,447:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 21:56:30,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 21:56:30,558:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 21:56:30,560:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 21:56:30,563:INFO:Preparing preprocessing pipeline...
2025-11-12 21:56:30,567:INFO:Set up simple imputation.
2025-11-12 21:56:30,576:INFO:Set up encoding of ordinal features.
2025-11-12 21:56:30,580:INFO:Set up encoding of categorical features.
2025-11-12 21:56:30,862:INFO:Finished creating preprocessing pipeline.
2025-11-12 21:56:30,893:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\usuario\AppData\Local\Temp\2\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['education_level',
                                             'marital_status',
                                             'income_category',
                                             'card_category'],
                                    transformer=OneHotEncoder(cols=['education_level',
                                                                    'marital_status',
                                                                    'income_category',
                                                                    'card_category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-11-12 21:56:30,893:INFO:Creating final display dataframe.
2025-11-12 21:56:31,146:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target    attrition_flag
2                   Target type            Binary
3           Original data shape       (10127, 21)
4        Transformed data shape       (10127, 38)
5   Transformed train set shape        (7088, 38)
6    Transformed test set shape        (3039, 38)
7              Numeric features                15
8          Categorical features                 5
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              04b1
2025-11-12 21:56:31,260:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 21:56:31,260:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 21:56:31,369:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 21:56:31,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-11-12 21:56:31,373:INFO:setup() successfully completed in 1.55s...............
2025-11-12 21:56:31,373:INFO:Initializing compare_models()
2025-11-12 21:56:31,373:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>, include=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>, 'include': None, 'exclude': ['ridge', 'dummy', 'svm', 'quadratic_discriminant_analysis'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['ridge', 'dummy', 'svm', 'quadratic_discriminant_analysis'])
2025-11-12 21:56:31,373:INFO:Checking exceptions
2025-11-12 21:56:31,389:INFO:Preparing display monitor
2025-11-12 21:56:31,397:INFO:Initializing Logistic Regression
2025-11-12 21:56:31,397:INFO:Total runtime is 0.0 minutes
2025-11-12 21:56:31,398:INFO:SubProcess create_model() called ==================================
2025-11-12 21:56:31,398:INFO:Initializing create_model()
2025-11-12 21:56:31,399:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE714F4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 21:56:31,399:INFO:Checking exceptions
2025-11-12 21:56:31,399:INFO:Importing libraries
2025-11-12 21:56:31,399:INFO:Copying training dataset
2025-11-12 21:56:31,419:INFO:Defining folds
2025-11-12 21:56:31,419:INFO:Declaring metric variables
2025-11-12 21:56:31,419:INFO:Importing untrained model
2025-11-12 21:56:31,419:INFO:Logistic Regression Imported successfully
2025-11-12 21:56:31,419:INFO:Starting cross validation
2025-11-12 21:56:31,424:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 21:56:42,783:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 21:56:42,783:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 21:56:42,785:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 21:56:42,785:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 21:56:42,785:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 21:56:42,786:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 21:56:42,786:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 21:56:42,786:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 21:56:42,786:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 21:56:42,785:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 21:56:43,464:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 21:56:43,589:INFO:Calculating mean and std
2025-11-12 21:56:43,594:INFO:Creating metrics dataframe
2025-11-12 21:56:43,599:INFO:Uploading results into container
2025-11-12 21:56:43,600:INFO:Uploading model into container now
2025-11-12 21:56:43,601:INFO:_master_model_container: 1
2025-11-12 21:56:43,601:INFO:_display_container: 2
2025-11-12 21:56:43,601:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-11-12 21:56:43,601:INFO:create_model() successfully completed......................................
2025-11-12 21:56:43,851:INFO:SubProcess create_model() end ==================================
2025-11-12 21:56:43,851:INFO:Creating metrics dataframe
2025-11-12 21:56:43,855:INFO:Initializing K Neighbors Classifier
2025-11-12 21:56:43,855:INFO:Total runtime is 0.20763866106669107 minutes
2025-11-12 21:56:43,855:INFO:SubProcess create_model() called ==================================
2025-11-12 21:56:43,855:INFO:Initializing create_model()
2025-11-12 21:56:43,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE714F4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 21:56:43,855:INFO:Checking exceptions
2025-11-12 21:56:43,855:INFO:Importing libraries
2025-11-12 21:56:43,855:INFO:Copying training dataset
2025-11-12 21:56:43,875:INFO:Defining folds
2025-11-12 21:56:43,877:INFO:Declaring metric variables
2025-11-12 21:56:43,877:INFO:Importing untrained model
2025-11-12 21:56:43,878:INFO:K Neighbors Classifier Imported successfully
2025-11-12 21:56:43,878:INFO:Starting cross validation
2025-11-12 21:56:43,882:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 21:56:46,930:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 21:56:47,144:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 21:56:47,174:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 21:56:47,205:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 21:56:47,210:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 21:56:47,236:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\_distutils_hack\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(

2025-11-12 21:56:48,178:INFO:Calculating mean and std
2025-11-12 21:56:48,183:INFO:Creating metrics dataframe
2025-11-12 21:56:48,188:INFO:Uploading results into container
2025-11-12 21:56:48,189:INFO:Uploading model into container now
2025-11-12 21:56:48,190:INFO:_master_model_container: 2
2025-11-12 21:56:48,190:INFO:_display_container: 2
2025-11-12 21:56:48,191:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-11-12 21:56:48,191:INFO:create_model() successfully completed......................................
2025-11-12 21:56:48,340:INFO:SubProcess create_model() end ==================================
2025-11-12 21:56:48,340:INFO:Creating metrics dataframe
2025-11-12 21:56:48,345:INFO:Initializing Naive Bayes
2025-11-12 21:56:48,345:INFO:Total runtime is 0.2824685970942179 minutes
2025-11-12 21:56:48,345:INFO:SubProcess create_model() called ==================================
2025-11-12 21:56:48,345:INFO:Initializing create_model()
2025-11-12 21:56:48,345:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE714F4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 21:56:48,345:INFO:Checking exceptions
2025-11-12 21:56:48,345:INFO:Importing libraries
2025-11-12 21:56:48,345:INFO:Copying training dataset
2025-11-12 21:56:48,366:INFO:Defining folds
2025-11-12 21:56:48,366:INFO:Declaring metric variables
2025-11-12 21:56:48,366:INFO:Importing untrained model
2025-11-12 21:56:48,367:INFO:Naive Bayes Imported successfully
2025-11-12 21:56:48,367:INFO:Starting cross validation
2025-11-12 21:56:48,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 21:56:48,685:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 21:56:48,699:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 21:56:48,706:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 21:56:48,710:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 21:56:48,715:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 21:56:48,717:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 21:56:48,721:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 21:56:48,726:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 21:56:48,734:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 21:56:48,751:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-11-12 21:56:48,767:INFO:Calculating mean and std
2025-11-12 21:56:48,770:INFO:Creating metrics dataframe
2025-11-12 21:56:48,774:INFO:Uploading results into container
2025-11-12 21:56:48,775:INFO:Uploading model into container now
2025-11-12 21:56:48,775:INFO:_master_model_container: 3
2025-11-12 21:56:48,775:INFO:_display_container: 2
2025-11-12 21:56:48,777:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-11-12 21:56:48,777:INFO:create_model() successfully completed......................................
2025-11-12 21:56:48,919:INFO:SubProcess create_model() end ==================================
2025-11-12 21:56:48,919:INFO:Creating metrics dataframe
2025-11-12 21:56:48,925:INFO:Initializing Decision Tree Classifier
2025-11-12 21:56:48,925:INFO:Total runtime is 0.29213034311930336 minutes
2025-11-12 21:56:48,925:INFO:SubProcess create_model() called ==================================
2025-11-12 21:56:48,925:INFO:Initializing create_model()
2025-11-12 21:56:48,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE714F4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 21:56:48,925:INFO:Checking exceptions
2025-11-12 21:56:48,925:INFO:Importing libraries
2025-11-12 21:56:48,925:INFO:Copying training dataset
2025-11-12 21:56:48,941:INFO:Defining folds
2025-11-12 21:56:48,944:INFO:Declaring metric variables
2025-11-12 21:56:48,944:INFO:Importing untrained model
2025-11-12 21:56:48,945:INFO:Decision Tree Classifier Imported successfully
2025-11-12 21:56:48,945:INFO:Starting cross validation
2025-11-12 21:56:48,949:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 21:56:49,419:INFO:Calculating mean and std
2025-11-12 21:56:49,422:INFO:Creating metrics dataframe
2025-11-12 21:56:49,427:INFO:Uploading results into container
2025-11-12 21:56:49,427:INFO:Uploading model into container now
2025-11-12 21:56:49,428:INFO:_master_model_container: 4
2025-11-12 21:56:49,429:INFO:_display_container: 2
2025-11-12 21:56:49,430:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=42, splitter='best')
2025-11-12 21:56:49,430:INFO:create_model() successfully completed......................................
2025-11-12 21:56:49,623:INFO:SubProcess create_model() end ==================================
2025-11-12 21:56:49,623:INFO:Creating metrics dataframe
2025-11-12 21:56:49,629:INFO:Initializing Random Forest Classifier
2025-11-12 21:56:49,629:INFO:Total runtime is 0.3038622577985127 minutes
2025-11-12 21:56:49,629:INFO:SubProcess create_model() called ==================================
2025-11-12 21:56:49,629:INFO:Initializing create_model()
2025-11-12 21:56:49,629:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE714F4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 21:56:49,629:INFO:Checking exceptions
2025-11-12 21:56:49,629:INFO:Importing libraries
2025-11-12 21:56:49,631:INFO:Copying training dataset
2025-11-12 21:56:49,651:INFO:Defining folds
2025-11-12 21:56:49,651:INFO:Declaring metric variables
2025-11-12 21:56:49,652:INFO:Importing untrained model
2025-11-12 21:56:49,653:INFO:Random Forest Classifier Imported successfully
2025-11-12 21:56:49,653:INFO:Starting cross validation
2025-11-12 21:56:49,656:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 21:56:51,749:INFO:Calculating mean and std
2025-11-12 21:56:51,753:INFO:Creating metrics dataframe
2025-11-12 21:56:51,756:INFO:Uploading results into container
2025-11-12 21:56:51,758:INFO:Uploading model into container now
2025-11-12 21:56:51,759:INFO:_master_model_container: 5
2025-11-12 21:56:51,759:INFO:_display_container: 2
2025-11-12 21:56:51,760:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=42, verbose=0,
                       warm_start=False)
2025-11-12 21:56:51,760:INFO:create_model() successfully completed......................................
2025-11-12 21:56:51,911:INFO:SubProcess create_model() end ==================================
2025-11-12 21:56:51,911:INFO:Creating metrics dataframe
2025-11-12 21:56:51,915:INFO:Initializing Quadratic Discriminant Analysis
2025-11-12 21:56:51,915:INFO:Total runtime is 0.3419729351997375 minutes
2025-11-12 21:56:51,915:INFO:SubProcess create_model() called ==================================
2025-11-12 21:56:51,918:INFO:Initializing create_model()
2025-11-12 21:56:51,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE714F4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 21:56:51,918:INFO:Checking exceptions
2025-11-12 21:56:51,918:INFO:Importing libraries
2025-11-12 21:56:51,918:INFO:Copying training dataset
2025-11-12 21:56:51,937:INFO:Defining folds
2025-11-12 21:56:51,937:INFO:Declaring metric variables
2025-11-12 21:56:51,937:INFO:Importing untrained model
2025-11-12 21:56:51,937:INFO:Quadratic Discriminant Analysis Imported successfully
2025-11-12 21:56:51,939:INFO:Starting cross validation
2025-11-12 21:56:51,943:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 21:56:52,232:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-12 21:56:52,233:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-12 21:56:52,233:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-12 21:56:52,233:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-12 21:56:52,234:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-12 21:56:52,235:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-12 21:56:52,235:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-12 21:56:52,236:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-12 21:56:52,248:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-11-12 21:56:52,355:INFO:Calculating mean and std
2025-11-12 21:56:52,357:INFO:Creating metrics dataframe
2025-11-12 21:56:52,362:INFO:Uploading results into container
2025-11-12 21:56:52,364:INFO:Uploading model into container now
2025-11-12 21:56:52,365:INFO:_master_model_container: 6
2025-11-12 21:56:52,366:INFO:_display_container: 2
2025-11-12 21:56:52,366:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-11-12 21:56:52,366:INFO:create_model() successfully completed......................................
2025-11-12 21:56:52,517:INFO:SubProcess create_model() end ==================================
2025-11-12 21:56:52,517:INFO:Creating metrics dataframe
2025-11-12 21:56:52,522:INFO:Initializing Ada Boost Classifier
2025-11-12 21:56:52,522:INFO:Total runtime is 0.3520810484886169 minutes
2025-11-12 21:56:52,522:INFO:SubProcess create_model() called ==================================
2025-11-12 21:56:52,524:INFO:Initializing create_model()
2025-11-12 21:56:52,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE714F4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 21:56:52,524:INFO:Checking exceptions
2025-11-12 21:56:52,524:INFO:Importing libraries
2025-11-12 21:56:52,524:INFO:Copying training dataset
2025-11-12 21:56:52,542:INFO:Defining folds
2025-11-12 21:56:52,543:INFO:Declaring metric variables
2025-11-12 21:56:52,543:INFO:Importing untrained model
2025-11-12 21:56:52,544:INFO:Ada Boost Classifier Imported successfully
2025-11-12 21:56:52,544:INFO:Starting cross validation
2025-11-12 21:56:52,548:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 21:56:52,812:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 21:56:52,813:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 21:56:52,813:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 21:56:52,813:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 21:56:52,813:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 21:56:52,815:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 21:56:52,817:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 21:56:52,818:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 21:56:52,818:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 21:56:52,824:WARNING:C:\Users\usuario\PycharmProjects\PythonProject\.venv\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-11-12 21:56:53,749:INFO:Calculating mean and std
2025-11-12 21:56:53,751:INFO:Creating metrics dataframe
2025-11-12 21:56:53,756:INFO:Uploading results into container
2025-11-12 21:56:53,757:INFO:Uploading model into container now
2025-11-12 21:56:53,758:INFO:_master_model_container: 7
2025-11-12 21:56:53,758:INFO:_display_container: 2
2025-11-12 21:56:53,758:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=42)
2025-11-12 21:56:53,759:INFO:create_model() successfully completed......................................
2025-11-12 21:56:53,909:INFO:SubProcess create_model() end ==================================
2025-11-12 21:56:53,909:INFO:Creating metrics dataframe
2025-11-12 21:56:53,914:INFO:Initializing Gradient Boosting Classifier
2025-11-12 21:56:53,914:INFO:Total runtime is 0.3752849141756693 minutes
2025-11-12 21:56:53,914:INFO:SubProcess create_model() called ==================================
2025-11-12 21:56:53,914:INFO:Initializing create_model()
2025-11-12 21:56:53,914:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE714F4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 21:56:53,914:INFO:Checking exceptions
2025-11-12 21:56:53,914:INFO:Importing libraries
2025-11-12 21:56:53,914:INFO:Copying training dataset
2025-11-12 21:56:53,935:INFO:Defining folds
2025-11-12 21:56:53,935:INFO:Declaring metric variables
2025-11-12 21:56:53,935:INFO:Importing untrained model
2025-11-12 21:56:53,937:INFO:Gradient Boosting Classifier Imported successfully
2025-11-12 21:56:53,937:INFO:Starting cross validation
2025-11-12 21:56:53,941:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 21:56:57,458:INFO:Calculating mean and std
2025-11-12 21:56:57,462:INFO:Creating metrics dataframe
2025-11-12 21:56:57,464:INFO:Uploading results into container
2025-11-12 21:56:57,464:INFO:Uploading model into container now
2025-11-12 21:56:57,467:INFO:_master_model_container: 8
2025-11-12 21:56:57,467:INFO:_display_container: 2
2025-11-12 21:56:57,468:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=42, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-11-12 21:56:57,468:INFO:create_model() successfully completed......................................
2025-11-12 21:56:57,608:INFO:SubProcess create_model() end ==================================
2025-11-12 21:56:57,608:INFO:Creating metrics dataframe
2025-11-12 21:56:57,612:INFO:Initializing Linear Discriminant Analysis
2025-11-12 21:56:57,612:INFO:Total runtime is 0.4369151830673217 minutes
2025-11-12 21:56:57,612:INFO:SubProcess create_model() called ==================================
2025-11-12 21:56:57,612:INFO:Initializing create_model()
2025-11-12 21:56:57,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE714F4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 21:56:57,612:INFO:Checking exceptions
2025-11-12 21:56:57,612:INFO:Importing libraries
2025-11-12 21:56:57,614:INFO:Copying training dataset
2025-11-12 21:56:57,630:INFO:Defining folds
2025-11-12 21:56:57,630:INFO:Declaring metric variables
2025-11-12 21:56:57,630:INFO:Importing untrained model
2025-11-12 21:56:57,631:INFO:Linear Discriminant Analysis Imported successfully
2025-11-12 21:56:57,631:INFO:Starting cross validation
2025-11-12 21:56:57,634:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 21:56:58,053:INFO:Calculating mean and std
2025-11-12 21:56:58,057:INFO:Creating metrics dataframe
2025-11-12 21:56:58,061:INFO:Uploading results into container
2025-11-12 21:56:58,062:INFO:Uploading model into container now
2025-11-12 21:56:58,062:INFO:_master_model_container: 9
2025-11-12 21:56:58,062:INFO:_display_container: 2
2025-11-12 21:56:58,063:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-11-12 21:56:58,063:INFO:create_model() successfully completed......................................
2025-11-12 21:56:58,213:INFO:SubProcess create_model() end ==================================
2025-11-12 21:56:58,213:INFO:Creating metrics dataframe
2025-11-12 21:56:58,217:INFO:Initializing Extra Trees Classifier
2025-11-12 21:56:58,217:INFO:Total runtime is 0.4470025897026061 minutes
2025-11-12 21:56:58,219:INFO:SubProcess create_model() called ==================================
2025-11-12 21:56:58,219:INFO:Initializing create_model()
2025-11-12 21:56:58,219:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE714F4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 21:56:58,219:INFO:Checking exceptions
2025-11-12 21:56:58,219:INFO:Importing libraries
2025-11-12 21:56:58,219:INFO:Copying training dataset
2025-11-12 21:56:58,237:INFO:Defining folds
2025-11-12 21:56:58,237:INFO:Declaring metric variables
2025-11-12 21:56:58,239:INFO:Importing untrained model
2025-11-12 21:56:58,239:INFO:Extra Trees Classifier Imported successfully
2025-11-12 21:56:58,239:INFO:Starting cross validation
2025-11-12 21:56:58,244:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 21:56:59,865:INFO:Calculating mean and std
2025-11-12 21:56:59,869:INFO:Creating metrics dataframe
2025-11-12 21:56:59,874:INFO:Uploading results into container
2025-11-12 21:56:59,876:INFO:Uploading model into container now
2025-11-12 21:56:59,877:INFO:_master_model_container: 10
2025-11-12 21:56:59,877:INFO:_display_container: 2
2025-11-12 21:56:59,878:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=42, verbose=0,
                     warm_start=False)
2025-11-12 21:56:59,878:INFO:create_model() successfully completed......................................
2025-11-12 21:57:00,035:INFO:SubProcess create_model() end ==================================
2025-11-12 21:57:00,035:INFO:Creating metrics dataframe
2025-11-12 21:57:00,041:INFO:Initializing Light Gradient Boosting Machine
2025-11-12 21:57:00,041:INFO:Total runtime is 0.47739365498224884 minutes
2025-11-12 21:57:00,041:INFO:SubProcess create_model() called ==================================
2025-11-12 21:57:00,043:INFO:Initializing create_model()
2025-11-12 21:57:00,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE714F4CD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 21:57:00,043:INFO:Checking exceptions
2025-11-12 21:57:00,043:INFO:Importing libraries
2025-11-12 21:57:00,043:INFO:Copying training dataset
2025-11-12 21:57:00,064:INFO:Defining folds
2025-11-12 21:57:00,064:INFO:Declaring metric variables
2025-11-12 21:57:00,064:INFO:Importing untrained model
2025-11-12 21:57:00,066:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-12 21:57:00,066:INFO:Starting cross validation
2025-11-12 21:57:00,070:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 21:57:19,974:INFO:Calculating mean and std
2025-11-12 21:57:19,978:INFO:Creating metrics dataframe
2025-11-12 21:57:19,982:INFO:Uploading results into container
2025-11-12 21:57:19,985:INFO:Uploading model into container now
2025-11-12 21:57:19,985:INFO:_master_model_container: 11
2025-11-12 21:57:19,985:INFO:_display_container: 2
2025-11-12 21:57:19,987:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-12 21:57:19,987:INFO:create_model() successfully completed......................................
2025-11-12 21:57:20,128:INFO:SubProcess create_model() end ==================================
2025-11-12 21:57:20,128:INFO:Creating metrics dataframe
2025-11-12 21:57:20,139:INFO:Initializing create_model()
2025-11-12 21:57:20,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 21:57:20,141:INFO:Checking exceptions
2025-11-12 21:57:20,141:INFO:Importing libraries
2025-11-12 21:57:20,141:INFO:Copying training dataset
2025-11-12 21:57:20,158:INFO:Defining folds
2025-11-12 21:57:20,158:INFO:Declaring metric variables
2025-11-12 21:57:20,159:INFO:Importing untrained model
2025-11-12 21:57:20,159:INFO:Declaring custom model
2025-11-12 21:57:20,161:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-12 21:57:20,165:INFO:Cross validation set to False
2025-11-12 21:57:20,165:INFO:Fitting Model
2025-11-12 21:57:20,371:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-12 21:57:20,373:INFO:[LightGBM] [Info] Number of positive: 1139, number of negative: 5949
2025-11-12 21:57:20,374:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001084 seconds.
2025-11-12 21:57:20,375:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-12 21:57:20,375:INFO:[LightGBM] [Info] Total Bins 2320
2025-11-12 21:57:20,376:INFO:[LightGBM] [Info] Number of data points in the train set: 7088, number of used features: 36
2025-11-12 21:57:20,376:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160694 -> initscore=-1.653072
2025-11-12 21:57:20,376:INFO:[LightGBM] [Info] Start training from score -1.653072
2025-11-12 21:57:21,845:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-12 21:57:21,845:INFO:create_model() successfully completed......................................
2025-11-12 21:57:22,012:INFO:_master_model_container: 11
2025-11-12 21:57:22,012:INFO:_display_container: 2
2025-11-12 21:57:22,012:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-12 21:57:22,012:INFO:compare_models() successfully completed......................................
2025-11-12 21:57:22,034:INFO:Initializing tune_model()
2025-11-12 21:57:22,036:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=30, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>)
2025-11-12 21:57:22,036:INFO:Checking exceptions
2025-11-12 21:57:22,049:INFO:Copying training dataset
2025-11-12 21:57:22,061:INFO:Checking base model
2025-11-12 21:57:22,062:INFO:Base model : Light Gradient Boosting Machine
2025-11-12 21:57:22,063:INFO:Declaring metric variables
2025-11-12 21:57:22,063:INFO:Defining Hyperparameters
2025-11-12 21:57:22,228:INFO:Tuning with n_jobs=-1
2025-11-12 21:57:22,228:INFO:Initializing RandomizedSearchCV
2025-11-12 22:04:54,780:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.2, 'actual_estimator__num_leaves': 40, 'actual_estimator__n_estimators': 160, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.4}
2025-11-12 22:04:54,787:INFO:Hyperparameter search completed
2025-11-12 22:04:54,787:INFO:SubProcess create_model() called ==================================
2025-11-12 22:04:54,790:INFO:Initializing create_model()
2025-11-12 22:04:54,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AE71517760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.2, 'num_leaves': 40, 'n_estimators': 160, 'min_split_gain': 0.4, 'min_child_samples': 6, 'learning_rate': 0.1, 'feature_fraction': 0.8, 'bagging_freq': 2, 'bagging_fraction': 0.4})
2025-11-12 22:04:54,791:INFO:Checking exceptions
2025-11-12 22:04:54,791:INFO:Importing libraries
2025-11-12 22:04:54,792:INFO:Copying training dataset
2025-11-12 22:04:54,817:INFO:Defining folds
2025-11-12 22:04:54,817:INFO:Declaring metric variables
2025-11-12 22:04:54,818:INFO:Importing untrained model
2025-11-12 22:04:54,818:INFO:Declaring custom model
2025-11-12 22:04:54,821:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-12 22:04:54,823:INFO:Starting cross validation
2025-11-12 22:04:54,827:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 22:05:17,180:INFO:Calculating mean and std
2025-11-12 22:05:17,182:INFO:Creating metrics dataframe
2025-11-12 22:05:17,188:INFO:Finalizing model
2025-11-12 22:05:17,403:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-12 22:05:17,403:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-12 22:05:17,403:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-12 22:05:17,418:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-12 22:05:17,420:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-12 22:05:17,421:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-12 22:05:17,421:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-12 22:05:17,421:INFO:[LightGBM] [Info] Number of positive: 1139, number of negative: 5949
2025-11-12 22:05:17,426:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002420 seconds.
2025-11-12 22:05:17,426:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-12 22:05:17,427:INFO:[LightGBM] [Info] Total Bins 2322
2025-11-12 22:05:17,427:INFO:[LightGBM] [Info] Number of data points in the train set: 7088, number of used features: 37
2025-11-12 22:05:17,429:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160694 -> initscore=-1.653072
2025-11-12 22:05:17,430:INFO:[LightGBM] [Info] Start training from score -1.653072
2025-11-12 22:05:18,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:18,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:19,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:19,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:19,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:19,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:19,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:19,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:19,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:19,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:19,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:19,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:19,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:19,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:19,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:19,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:19,089:INFO:Uploading results into container
2025-11-12 22:05:19,092:INFO:Uploading model into container now
2025-11-12 22:05:19,093:INFO:_master_model_container: 12
2025-11-12 22:05:19,093:INFO:_display_container: 3
2025-11-12 22:05:19,094:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-12 22:05:19,095:INFO:create_model() successfully completed......................................
2025-11-12 22:05:19,337:INFO:SubProcess create_model() end ==================================
2025-11-12 22:05:19,339:INFO:choose_better activated
2025-11-12 22:05:19,340:INFO:SubProcess create_model() called ==================================
2025-11-12 22:05:19,341:INFO:Initializing create_model()
2025-11-12 22:05:19,341:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 22:05:19,341:INFO:Checking exceptions
2025-11-12 22:05:19,343:INFO:Importing libraries
2025-11-12 22:05:19,343:INFO:Copying training dataset
2025-11-12 22:05:19,363:INFO:Defining folds
2025-11-12 22:05:19,363:INFO:Declaring metric variables
2025-11-12 22:05:19,363:INFO:Importing untrained model
2025-11-12 22:05:19,363:INFO:Declaring custom model
2025-11-12 22:05:19,365:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-12 22:05:19,367:INFO:Starting cross validation
2025-11-12 22:05:19,369:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-11-12 22:05:57,557:INFO:Calculating mean and std
2025-11-12 22:05:57,559:INFO:Creating metrics dataframe
2025-11-12 22:05:57,562:INFO:Finalizing model
2025-11-12 22:05:57,767:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-12 22:05:57,769:INFO:[LightGBM] [Info] Number of positive: 1139, number of negative: 5949
2025-11-12 22:05:57,773:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002194 seconds.
2025-11-12 22:05:57,773:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-12 22:05:57,773:INFO:[LightGBM] [Info] Total Bins 2320
2025-11-12 22:05:57,774:INFO:[LightGBM] [Info] Number of data points in the train set: 7088, number of used features: 36
2025-11-12 22:05:57,774:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160694 -> initscore=-1.653072
2025-11-12 22:05:57,774:INFO:[LightGBM] [Info] Start training from score -1.653072
2025-11-12 22:05:58,810:INFO:Uploading results into container
2025-11-12 22:05:58,812:INFO:Uploading model into container now
2025-11-12 22:05:58,813:INFO:_master_model_container: 13
2025-11-12 22:05:58,813:INFO:_display_container: 4
2025-11-12 22:05:58,814:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-12 22:05:58,814:INFO:create_model() successfully completed......................................
2025-11-12 22:05:58,962:INFO:SubProcess create_model() end ==================================
2025-11-12 22:05:58,964:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=42, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.8911
2025-11-12 22:05:58,965:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.892
2025-11-12 22:05:58,967:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2025-11-12 22:05:58,967:INFO:choose_better completed
2025-11-12 22:05:58,975:INFO:_master_model_container: 13
2025-11-12 22:05:58,975:INFO:_display_container: 3
2025-11-12 22:05:58,976:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-12 22:05:58,976:INFO:tune_model() successfully completed......................................
2025-11-12 22:05:59,092:INFO:Initializing finalize_model()
2025-11-12 22:05:59,093:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>, estimator=LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2025-11-12 22:05:59,093:INFO:Finalizing LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-11-12 22:05:59,104:INFO:Initializing create_model()
2025-11-12 22:05:59,104:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AE6C4FD220>, estimator=LGBMClassifier(bagging_fraction=0.4, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=160, n_jobs=-1, num_leaves=40, objective=None,
               random_state=42, reg_alpha=0.2, reg_lambda=0.1, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2025-11-12 22:05:59,106:INFO:Checking exceptions
2025-11-12 22:05:59,106:INFO:Importing libraries
2025-11-12 22:05:59,106:INFO:Copying training dataset
2025-11-12 22:05:59,108:INFO:Defining folds
2025-11-12 22:05:59,108:INFO:Declaring metric variables
2025-11-12 22:05:59,108:INFO:Importing untrained model
2025-11-12 22:05:59,108:INFO:Declaring custom model
2025-11-12 22:05:59,110:INFO:Light Gradient Boosting Machine Imported successfully
2025-11-12 22:05:59,115:INFO:Cross validation set to False
2025-11-12 22:05:59,115:INFO:Fitting Model
2025-11-12 22:05:59,348:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-12 22:05:59,348:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-12 22:05:59,348:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-12 22:05:59,366:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-11-12 22:05:59,369:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2025-11-12 22:05:59,369:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2025-11-12 22:05:59,370:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2025-11-12 22:05:59,370:INFO:[LightGBM] [Info] Number of positive: 1627, number of negative: 8500
2025-11-12 22:05:59,376:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003056 seconds.
2025-11-12 22:05:59,376:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-11-12 22:05:59,376:INFO:[LightGBM] [Info] Total Bins 2324
2025-11-12 22:05:59,378:INFO:[LightGBM] [Info] Number of data points in the train set: 10127, number of used features: 37
2025-11-12 22:05:59,379:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160660 -> initscore=-1.653328
2025-11-12 22:05:59,379:INFO:[LightGBM] [Info] Start training from score -1.653328
2025-11-12 22:05:59,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:59,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:59,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:59,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:05:59,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-11-12 22:06:00,601:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-12 22:06:00,601:INFO:create_model() successfully completed......................................
2025-11-12 22:06:00,733:INFO:_master_model_container: 13
2025-11-12 22:06:00,733:INFO:_display_container: 3
2025-11-12 22:06:00,773:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-12 22:06:00,773:INFO:finalize_model() successfully completed......................................
2025-11-12 22:06:00,966:INFO:Initializing save_model()
2025-11-12 22:06:00,966:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=pycaret_best_automl_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\usuario\AppData\Local\Temp\2\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total...
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['education_level',
                                             'marital_status',
                                             'income_category',
                                             'card_category'],
                                    transformer=OneHotEncoder(cols=['education_level',
                                                                    'marital_status',
                                                                    'income_category',
                                                                    'card_category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-11-12 22:06:00,966:INFO:Adding model into prep_pipe
2025-11-12 22:06:00,966:WARNING:Only Model saved as it was a pipeline.
2025-11-12 22:06:00,999:INFO:pycaret_best_automl_model.pkl saved in current working directory
2025-11-12 22:06:01,035:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['clientnum', 'customer_age',
                                             'dependent_count',
                                             'months_on_book',
                                             'total_relationship_count',
                                             'months_inactive_12_mon',
                                             'contacts_count_12_mon',
                                             'credit_limit',
                                             'total_revolving_bal',
                                             'avg_open_to_buy',
                                             'total_amt_chng_q4_q1',
                                             'total_trans_amt',
                                             'total_tr...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.8,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=6,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=160, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=42, reg_alpha=0.2,
                                reg_lambda=0.1, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-11-12 22:06:01,035:INFO:save_model() successfully completed......................................
2025-11-12 22:06:01,201:INFO:Initializing load_model()
2025-11-12 22:06:01,201:INFO:load_model(model_name=pycaret_best_automl_model, platform=None, authentication=None, verbose=False)
